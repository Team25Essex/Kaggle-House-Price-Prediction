{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chCZBnhrD9iu",
        "colab_type": "text"
      },
      "source": [
        "Importing all the libraries and models used:\n",
        "\n",
        "*   Pandas python library for data reading, analysis etc.\n",
        "*   SKLearn for 2 out of the 3 models we used\n",
        "*   XGBoost for our third model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rzpr5gY-06k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model  import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBRegressor\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJFY5JabHWyv",
        "colab_type": "text"
      },
      "source": [
        "**Data processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WOocEceG3OC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reading data:\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "train.dropna(axis=0,subset=['SalePrice'],inplace=True)\n",
        "Train_y = train.SalePrice   #The target columns without NaN\n",
        "train.drop(['SalePrice'],axis=1,inplace=True)  #The predictive columns\n",
        "#for category part:\n",
        "drop_X = train.select_dtypes(include=['object'])\n",
        "drop_test_X = test.select_dtypes(include=['object'])\n",
        "#drop bad predictive value for LableEncoder\n",
        "Object_Columns=[]\n",
        "for columns in train.columns:\n",
        "    if train[columns].dtype == 'object':\n",
        "        Object_Columns.append(columns)\n",
        "good_columns=[]\n",
        "for columns in Object_Columns:\n",
        "    if set(train[columns]) == set(test[columns]):\n",
        "        good_columns.append(columns)\n",
        "bad_columns = list(set(Object_Columns)-set(good_columns))\n",
        "a=drop_X.drop(bad_columns,axis=1)\n",
        "b=drop_test_X.drop(bad_columns,axis=1)\n",
        "\n",
        "#fill the mising value using SimpleImputer:\n",
        "SI= SimpleImputer(strategy='constant',fill_value='None')\n",
        "SI_X = pd.DataFrame(SI.fit_transform(a))\n",
        "SI_Test_X= pd.DataFrame(SI.fit_transform(b))\n",
        "SI_X.columns = a.columns\n",
        "SI_Test_X.columns = b.columns\n",
        "#encode the category data:\n",
        "LE=LabelEncoder()\n",
        "for columns in set(good_columns):\n",
        "     a[columns] = LE.fit_transform(SI_X[columns])\n",
        "     b[columns] = LE.transform(SI_Test_X[columns])\n",
        "\n",
        "#for numerical part:\n",
        "number_X = train.select_dtypes(exclude=['object'])\n",
        "number_test_X = test.select_dtypes(exclude=['object'])\n",
        "#fill the mising value using SimpleImputer:\n",
        "SI_Median = SimpleImputer(strategy='most_frequent')\n",
        "SI_Median_X = pd.DataFrame(SI_Median.fit_transform(number_X))\n",
        "SI_Median_test_X = pd.DataFrame(SI_Median.transform(number_test_X))\n",
        "SI_Median_X.columns = number_X.columns\n",
        "SI_Median_test_X.columns = number_test_X.columns\n",
        "\n",
        "#combine numerical part and categorical part:\n",
        "union_x=pd.concat([SI_Median_X,a],axis=1)\n",
        "union_test_x=pd.concat([SI_Median_test_X,b],axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXTV45zSH7f5",
        "colab_type": "text"
      },
      "source": [
        "**Implementation of all three models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll2q8BBiHlzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using Linear Regression model:\n",
        "bestm1=LinearRegression()\n",
        "bestm1.fit(union_x,Train_y)\n",
        "bestprediction1=bestm1.predict(union_test_x)\n",
        "#RandomTreeRegressor\n",
        "\n",
        "bestm2 = RandomForestRegressor(random_state=5)\n",
        "print(bestm2)\n",
        "bestm2.fit(union_x,Train_y)\n",
        "bestprediction2=bestm2.predict(union_test_x)\n",
        "#XGBOOST\n",
        "train_x, x_val, train_y, y_val = train_test_split(union_x, Train_y, train_size=0.8, test_size=0.2,\n",
        "                                                      random_state=7)\n",
        "my_model = XGBRegressor(n_estimators=2000,objective ='reg:squarederror', learning_rate=0.1, n_jobs=10)\n",
        "my_model.fit(train_x, train_y, \n",
        "             early_stopping_rounds=5, \n",
        "             eval_set=[(x_val, y_val)], \n",
        "             verbose=False)\n",
        "bestprediction3=my_model.predict(union_test_x)\n",
        "\n",
        "bestprediction=(bestprediction2+bestprediction3+bestprediction1)/3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibDDVxOGIDhK",
        "colab_type": "text"
      },
      "source": [
        "**Outputing the predictions** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpPwS65eD3Nm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "23a54de4-7b45-41df-d33d-7e35d04cccff"
      },
      "source": [
        "predictionframe = pd.DataFrame({'Id':test.Id,\n",
        "                       'SalePrice': bestprediction})\n",
        "predictionframe.to_csv('submission.csv', index=False)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
            "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "                      max_samples=None, min_impurity_decrease=0.0,\n",
            "                      min_impurity_split=None, min_samples_leaf=1,\n",
            "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
            "                      random_state=5, verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
            "  if getattr(data, 'base', None) is not None and \\\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}