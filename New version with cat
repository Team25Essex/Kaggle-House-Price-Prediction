#!pip install category_encoders                                          if you are using colab, unlock these line to use CE encoder!
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model  import LinearRegression
from sklearn.model_selection import cross_val_score
from xgboost import XGBRegressor
import lightgbm as lgb
from lightgbm import LGBMRegressor 
import category_encoders as ce
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import SelectFromModel
from sklearn.multiclass import OneVsRestClassifier
import numpy as np
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import seaborn as sns
def Features(x, y):
        
        logistic = LogisticRegression(C=0.35, penalty="l1",solver='liblinear', random_state=5).fit(x, y)
        model = SelectFromModel(logistic, prefit=True)
        x_new = model.transform(x)
    
        # Get back the kept features as a DataFrame with dropped columns as all 0s
        selected_features = pd.DataFrame(model.inverse_transform(x_new), 
                                        index=x.index,
                                        columns=x.columns)
       
        # Dropped columns have values of all 0s, keep other columns 
        good_columns = selected_features.columns[selected_features.var() != 0]
        print (good_columns)
        return good_columns
    
    
def Check(train_train_x,train_train_y,List):
 times = KFold(n_splits=5, shuffle=True, random_state=10)
 for a in List:
  rmse= np.sqrt(-cross_val_score(a, np.log1p(train_train_x), np.log1p(train_train_y), scoring="neg_mean_squared_error",cv=times,n_jobs=-1))
  print('The machine for cross_val_score is:',a,'The score is:',rmse.mean())
 return rmse


#index 1 = return average, index 2 = return emsambered stacking.  
def ensemble(L_bestprediction, index,L_portion = []) :
  if index == 1:
        suma = 0
        for a in L_bestprediction:
            suma += a
        average = suma/len(L_bestprediction)
        return average
  elif index == 2:
        c=0
        y=0
        for b in L_bestprediction:
            if y==0:
                d = b[:int(b.size*L_portion[0])]
                y+=1
                continue
            elif y>0:
                sume = 0
                L_portion[c] += sume
                d = np.hstack((d,b[int(b.size*(L_portion[c])):int(b.size*(L_portion[c]+L_portion[c+1]))]))
                print(d.shape)
                c+=1
        return d

    
#exclude any outlier in the numerical part which helps to improve the accuracy of data.
def outlier(x):
    y=np.array(x,dtype=np.int)
    g=np.array(x,dtype=np.int)
    x=pd.DataFrame(x,dtype=np.int)
    Q1 = x.quantile(0.25)
    Q2 = x.quantile(0.5)
    Q3 = x.quantile(0.75)
    IQR = float(Q3 - Q1)
    c=[]
    for i in range(len(x)):
     y[i] = (y[i] < (Q1 - 1.5 * IQR)) | (y[i] > (Q3 + 1.5 * IQR))
     if y[i] == True:
        g[i]= int(Q2)
    g = pd.DataFrame(g,dtype=np.int)
    return g


test = pd.read_csv("../input/house-prices-advanced-regression-techniques/test.csv")
test2 = test.copy()
train = pd.read_csv("../input/house-prices-advanced-regression-techniques/train.csv")
train2=train.copy()
train.dropna(axis=0,subset=['SalePrice'],inplace=True)
train_y = train.SalePrice   #The target columns without NaN
Train_y= np.log1p(train_y)
train.drop(['Id','Street','Utilities','LowQualFinSF','3SsnPorch','PoolArea','PoolQC'],axis=1,inplace=True)
test.drop(['Id','Street','Utilities','LowQualFinSF','3SsnPorch','PoolArea','PoolQC'],axis=1,inplace=True)
train.drop(['SalePrice'],axis=1,inplace=True)  #The predictive columns


#for category part:
drop_X = train.select_dtypes(include=['object'])
drop_test_X = test.select_dtypes(include=['object'])


#fill the mising value using SimpleImputer:
SI= SimpleImputer(strategy='constant',fill_value='None')
SI_X = pd.DataFrame(SI.fit_transform(drop_X))
SI_Test_X= pd.DataFrame(SI.fit_transform(drop_test_X))
SI_X.columns = drop_X.columns
SI_Test_X.columns = drop_test_X.columns



#for numerical part:
number_X = train.select_dtypes(exclude=['object'])
number_test_X = test.select_dtypes(exclude=['object'])
#fill the mising value using SimpleImputer:
SI_Median = SimpleImputer(strategy='constant',fill_value=0)
SI_Median_X = pd.DataFrame(SI_Median.fit_transform(number_X))
SI_Median_test_X = pd.DataFrame(SI_Median.transform(number_test_X))
SI_Median_X.columns = number_X.columns
SI_Median_test_X.columns = number_test_X.columns

#Exclude Outlier:
for i in SI_Median_X.columns:
    SI_Median_X[i]=pd.DataFrame(outlier(SI_Median_X[i]))

#combine numerical part and categorical part:
union_x=pd.concat([SI_X,SI_Median_X],axis=1)
UNION_TEST_X=pd.concat([SI_Test_X,SI_Median_test_X],axis=1)
LIGHT_TRAIN_X=pd.concat([union_x,train2['SalePrice']],axis=1)


#New columns
##Total House Area = basement area+ First Floor area + Second Floor area
LIGHT_TRAIN_X["Total_House_Area"] = LIGHT_TRAIN_X["TotalBsmtSF"].astype(int) + LIGHT_TRAIN_X["1stFlrSF"].astype(int) + LIGHT_TRAIN_X["2ndFlrSF"].astype(int)   
##Total living Area = basement area+ First Floor area + Second Floor area + Garage Location area
LIGHT_TRAIN_X["Total_Area"] = LIGHT_TRAIN_X["TotalBsmtSF"] + LIGHT_TRAIN_X["1stFlrSF"] + LIGHT_TRAIN_X["2ndFlrSF"] + LIGHT_TRAIN_X["GarageArea"]
##Overall Quality for the House = Total House Area * the rates of overall material
LIGHT_TRAIN_X["Overall_Qality_of_Whole_House"] = LIGHT_TRAIN_X["Total_House_Area"] * LIGHT_TRAIN_X["OverallQual"] 
##Overall Quality of Ground Area = Ground Area * the rates of overall material
LIGHT_TRAIN_X["Overall_Quality_of_Ground_Area"] = LIGHT_TRAIN_X["GrLivArea"] * LIGHT_TRAIN_X["OverallQual"] 
##Total house area sorted by the zone= The zoning type of the house * totalhouse area 
LIGHT_TRAIN_X["House_Area_Zone"] = LIGHT_TRAIN_X["MSZoning"] * LIGHT_TRAIN_X["Total_House_Area"].astype(int)
##Overall Quality for different Zoning classification of the Sale = The zoning type of the house * the rates of overall material
LIGHT_TRAIN_X["Overall_Quality_of_Zone"] = LIGHT_TRAIN_X["MSZoning"] + LIGHT_TRAIN_X["OverallQual"].astype(str) 
##The zoning type sorted by built year = The zoning type of the house * Original construction date 
LIGHT_TRAIN_X["Zone_Year_Built"] = LIGHT_TRAIN_X["MSZoning"] + LIGHT_TRAIN_X["YearBuilt"].astype(str) 
##Total house area sorted by its Location in the city=Physical locations within that city * Total House Area
LIGHT_TRAIN_X["House_Area_Neighborhood"] = LIGHT_TRAIN_X["Neighborhood"] * LIGHT_TRAIN_X["Total_House_Area"] 
##Overall Quality for different physical locations in the city = Physical locations within that city * the rates of overall material
LIGHT_TRAIN_X["Overall_Quality_of_Neighborhood"] = LIGHT_TRAIN_X["Neighborhood"] + LIGHT_TRAIN_X["OverallQual"].astype(str)  
##The physical locations sorted by year built = Physical locations within that city + Original construction date 
LIGHT_TRAIN_X["Neighborhood_Year_Built"] = LIGHT_TRAIN_X["Neighborhood"] + LIGHT_TRAIN_X["YearBuilt"].astype(str)  
##Overall Quality for type 1 finished basement area = type 1 finished basement area * the rates of overall material
LIGHT_TRAIN_X["Overall_Quality_Type1_finished_basement"] = LIGHT_TRAIN_X["BsmtFinSF1"] * LIGHT_TRAIN_X["OverallQual"] 
##Total House area sorted by Home functionality = Home functionality(Whether it has deduction) * Total House Area
LIGHT_TRAIN_X["House_Area_functionality"] = LIGHT_TRAIN_X["Functional"] * LIGHT_TRAIN_X["Total_House_Area"] 
##Overall Quality for home functionality = Home functionality * the rates of overall material
LIGHT_TRAIN_X["Overall_Quality_functionality"] = LIGHT_TRAIN_X["Functional"] + LIGHT_TRAIN_X["OverallQual"].astype(str)  
##Overall Quality for Lot size/area = Lot size *  the rates of overall material
LIGHT_TRAIN_X["Overall_Quality_Lot_Area"] = LIGHT_TRAIN_X["LotArea"] * LIGHT_TRAIN_X["OverallQual"].astype(int) 
##Total House Area added with Lot Area = Total House Area + Lot size
LIGHT_TRAIN_X["Total_House_add_Lot_Area"] = LIGHT_TRAIN_X["Total_House_Area"] + LIGHT_TRAIN_X["LotArea"] 
##Total House Area sorted by its proximity = House's proximity(where the house is adjacent to) * Total House Area
LIGHT_TRAIN_X["Total_House_Condition1"] = LIGHT_TRAIN_X["Condition1"] * LIGHT_TRAIN_X["Total_House_Area"] 	
##Overall Quality for the house's proximity = House's proximity + the rates of overall material
LIGHT_TRAIN_X["Overall_Quality_Condition1"] = LIGHT_TRAIN_X["Condition1"] + LIGHT_TRAIN_X["OverallQual"].astype(str)  
##Basement total area= Type 1 basement total area+ type 2 basement total area + unfinished square feet of basement area
LIGHT_TRAIN_X["Basement_total_area"] = LIGHT_TRAIN_X["BsmtFinSF1"] + LIGHT_TRAIN_X["BsmtFinSF2"] + LIGHT_TRAIN_X["BsmtUnfSF"]  
##Total Department Area = Total basement area + first floor area +second floor area+ garage area+ open porch area + Enclosed porch area + screen porch area
LIGHT_TRAIN_X["TotalPlace"] = LIGHT_TRAIN_X["TotalBsmtSF"] + LIGHT_TRAIN_X["1stFlrSF"] + LIGHT_TRAIN_X["2ndFlrSF"] + LIGHT_TRAIN_X["GarageArea"] + LIGHT_TRAIN_X["OpenPorchSF"]+LIGHT_TRAIN_X["EnclosedPorch"]+LIGHT_TRAIN_X["ScreenPorch"]
## Add the same columns to test dataset as above
UNION_TEST_X["Total_House_Area"] = UNION_TEST_X["TotalBsmtSF"].astype(int) + UNION_TEST_X["1stFlrSF"].astype(int) + UNION_TEST_X["2ndFlrSF"].astype(int) 
UNION_TEST_X["Total_Area"] = UNION_TEST_X["TotalBsmtSF"] + UNION_TEST_X["1stFlrSF"] + UNION_TEST_X["2ndFlrSF"] + UNION_TEST_X["GarageArea"]
UNION_TEST_X["Overall_Qality_of_Whole_House"] = UNION_TEST_X["Total_House_Area"] * UNION_TEST_X["OverallQual"] 
UNION_TEST_X["Overall_Quality_of_Ground_Area"] = UNION_TEST_X["GrLivArea"] * UNION_TEST_X["OverallQual"] 
UNION_TEST_X["House_Area_Zone"] = UNION_TEST_X["MSZoning"] * UNION_TEST_X["Total_House_Area"].astype(int) 
UNION_TEST_X["Overall_Quality_of_Zone"] = UNION_TEST_X["MSZoning"] + UNION_TEST_X["OverallQual"].astype(str) 
UNION_TEST_X["Zone_Year_Built"] = UNION_TEST_X["MSZoning"] + UNION_TEST_X["YearBuilt"].astype(str)  
UNION_TEST_X["House_Area_Neighborhood"] = UNION_TEST_X["Neighborhood"] * UNION_TEST_X["Total_House_Area"] 
UNION_TEST_X["Overall_Quality_of_Neighborhood"] = UNION_TEST_X["Neighborhood"] + UNION_TEST_X["OverallQual"].astype(str)   
UNION_TEST_X["Neighborhood_Year_Built"] = UNION_TEST_X["Neighborhood"] + UNION_TEST_X["YearBuilt"].astype(str)   
UNION_TEST_X["Overall_Quality_Type1_finished_basement"] = UNION_TEST_X["BsmtFinSF1"] * UNION_TEST_X["OverallQual"] 
UNION_TEST_X["House_Area_functionality"] = UNION_TEST_X["Functional"] * UNION_TEST_X["Total_House_Area"] 
UNION_TEST_X["Overall_Quality_functionality"] = UNION_TEST_X["Functional"] + UNION_TEST_X["OverallQual"].astype(str)   
UNION_TEST_X["Overall_Quality_Lot_Area"] = UNION_TEST_X["LotArea"] * UNION_TEST_X["OverallQual"].astype(int) 
UNION_TEST_X["Total_House_add_Lot_Area"] = UNION_TEST_X["Total_House_Area"] + UNION_TEST_X["LotArea"] 
UNION_TEST_X["Total_House_Condition1"] = UNION_TEST_X["Condition1"] * UNION_TEST_X["Total_House_Area"] 
UNION_TEST_X["Overall_Quality_Condition1"] = UNION_TEST_X["Condition1"] + UNION_TEST_X["OverallQual"].astype(str) 
UNION_TEST_X["Basement_total_area"] = UNION_TEST_X["BsmtFinSF1"] + UNION_TEST_X["BsmtFinSF2"] + UNION_TEST_X["BsmtUnfSF"] 
UNION_TEST_X["TotalPlace"] = UNION_TEST_X["TotalBsmtSF"] + UNION_TEST_X["1stFlrSF"] + UNION_TEST_X["2ndFlrSF"] + UNION_TEST_X["GarageArea"] + UNION_TEST_X["OpenPorchSF"]+UNION_TEST_X["EnclosedPorch"]+UNION_TEST_X["ScreenPorch"]

#encode categorical columns with CatEncoder and log the columns that has positive skewness:

Numeric= UNION_TEST_X.select_dtypes(exclude=['object'])
categorical = UNION_TEST_X.select_dtypes(include=['object']).columns
CE = ce.CatBoostEncoder(cols=categorical)
CE.fit(LIGHT_TRAIN_X[categorical], LIGHT_TRAIN_X['SalePrice'])
LIGHT_TRAIN_X[categorical] = CE.transform(LIGHT_TRAIN_X[categorical])
UNION_TEST_X[categorical] = CE.transform(UNION_TEST_X[categorical])
for a in UNION_TEST_X.columns:
    if a in Numeric.columns and abs(LIGHT_TRAIN_X[a].skew(axis=0))>=1:
        LIGHT_TRAIN_X[a]=np.log1p(LIGHT_TRAIN_X[a])
    elif a not in Numeric.columns:
            if abs(LIGHT_TRAIN_X[a].skew(axis=0))>=1:
                LIGHT_TRAIN_X[a]=np.log1p(LIGHT_TRAIN_X[a])
for a in UNION_TEST_X.columns:
    if a in Numeric.columns and abs(UNION_TEST_X[a].skew(axis=0))>=1 :
        UNION_TEST_X[a]=np.log1p(UNION_TEST_X[a])
    elif a not in Numeric.columns:
            if abs(UNION_TEST_X[a].skew(axis=0))>=1:
                UNION_TEST_X[a]=np.log1p(UNION_TEST_X[a])


#Split the datasize
valid_fraction = 0.2741
valid_size = int(len(union_x) * valid_fraction)
train_train = LIGHT_TRAIN_X[:-2 * valid_size]
train_valid = LIGHT_TRAIN_X[-2 * valid_size:]
feature_cols = train_train.columns.drop('SalePrice')
LIGHT_TRAIN_X = train_train[feature_cols]
LIGHT_VALID_X = train_valid[feature_cols]
train_train_y_1 = train_train['SalePrice']
train_valid_y_1 = train_valid['SalePrice']
train_train_y = np.log1p(train_train_y_1)
train_valid_y = np.log1p(train_valid_y_1)
for each in [train_train, train_valid]:
    print(each['SalePrice'].mean())




#Regularization and remain the good columns:
Object_Columns=Features(LIGHT_TRAIN_X,train_train_y_1)
#Object_Columns=['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig',
#       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',
#       'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',
#       'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',
#       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating',
#       'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional',
#       'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',
#       'PavedDrive', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition',
#       'LotArea', 'BsmtFinSF2', 'BsmtUnfSF', '2ndFlrSF', 'GarageYrBlt',
#       'WoodDeckSF', 'MiscVal', '+_TotalHouse_OverallQual',
#       '+_GrLivArea_OverallQual', '+_oMSZoning_TotalHouse',
#       '+_oMSZoning_OverallQual', '+_oMSZoning_YearBuilt',
#       '+_oNeighborhood_TotalHouse', '+_oNeighborhood_OverallQual',
#       '+_oNeighborhood_YearBuilt', '+_BsmtFinSF1_OverallQual',
#       '-_oFunctional_TotalHouse', '-_oFunctional_OverallQual',
#       '-_LotArea_OverallQual', '-_TotalHouse_LotArea',
#       '-_oCondition1_TotalHouse', '-_oCondition1_OverallQual', 'TotalPlace']
LIGHT_TRAIN_X = LIGHT_TRAIN_X[Object_Columns]
LIGHT_VALID_X = LIGHT_VALID_X[Object_Columns]
UNION_TEST_X = UNION_TEST_X[Object_Columns] 

#preprocessing the data to have all datas in the same standard, also known as normalization
scalar = StandardScaler()
standard_x =  pd.DataFrame(data=scalar.fit(LIGHT_TRAIN_X).transform(LIGHT_TRAIN_X), columns=LIGHT_TRAIN_X.columns[:])
standard_valid_x=pd.DataFrame(data=scalar.fit(LIGHT_VALID_X).transform(LIGHT_VALID_X), columns=LIGHT_VALID_X.columns[:])
standard_test_x = pd.DataFrame(data=scalar.fit(UNION_TEST_X).transform(UNION_TEST_X), columns=UNION_TEST_X.columns[:])

#PCA
pca = PCA(n_components= 0.965)
Remained_train_X = pca.fit_transform(standard_x)
Remained_train_X = pd.DataFrame(np.reshape(Remained_train_X,(660,int(Remained_train_X.size/660))),columns=LIGHT_TRAIN_X.columns[:int(Remained_train_X.size/660)])
Remained_valid_X = pca.transform(standard_valid_x)
Remained_valid_X = pd.DataFrame(np.reshape(Remained_valid_X,(800,int(Remained_valid_X.size/800))),columns=LIGHT_TRAIN_X.columns[:int(Remained_valid_X.size/800)])
Remained_test_X = pca.transform(standard_test_x)
Remained_test_X = pd.DataFrame(data=np.reshape(Remained_test_X,(1459,int(Remained_test_X.size/1459))),columns=LIGHT_TRAIN_X.columns[:int(Remained_test_X.size/1459)])

#Light
#prepare_new = LGBMRegressor(metric='mae',num_leaves= 60,objective='regression', learning_rate=0.01, n_estimators=1000)
prepare = LGBMRegressor(metric='mae',num_leaves= 60,objective='regression', learning_rate=0.01, n_estimators=20000)
prepare.fit(LIGHT_TRAIN_X,train_train_y,eval_set=[(LIGHT_VALID_X,train_valid_y)], early_stopping_rounds=100)
bestprediction4 = prepare.predict(UNION_TEST_X)

#XGBOOST
#my_model_new = XGBRegressor(n_estimators=1000,objective ='reg:squarederror', learning_rate=0.01)
#my_model = XGBRegressor(n_estimators=20000,objective ='reg:squarederror', learning_rate=0.01)
#my_model.fit(Remained_train_X, train_train_y,early_stopping_rounds=100,eval_set=[(Remained_valid_X, train_valid_y)], verbose=False)
#bestprediction3=my_model.predict(Remained_test_X)


#Using Linear Regression model:
#bestm1=LinearRegression()
#bestm1.fit(Remained_train_X,train_train_y)
#bestprediction1=bestm1.predict(Remained_test_X)


#RandomTreeRegressor
#bestm2 = RandomForestRegressor(random_state=5)
#bestm2.fit(Remained_train_X,train_train_y)
#bestprediction2=bestm2.predict(Remained_test_X)

#List = [prepare_new,my_model_new,bestm1,bestm2]
#Check(np.expm1(Remained_train_X),train_train_y_1,List)


#Using Stack to combine each portion of estimator's predition together 
List1=[bestprediction4]  # List of the model to pass to the function
Portion= [0.5,0.25,0.25]   #List of proportion for the xList of the model, must add up to 1. for this example, bestprediction4 will have 0.7 size.
c= ensemble(List1,1)
bestprediction=np.expm1(bestprediction4)

predictionframe = pd.DataFrame({'Id':test2.Id,
                       'SalePrice': bestprediction})
predictionframe.to_csv('submission.csv', index=False)
