import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model  import LinearRegression
from sklearn.model_selection import cross_val_score
from xgboost import XGBRegressor
import lightgbm as lgb
from lightgbm import LGBMRegressor 
import category_encoders as ce
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import SelectFromModel
from sklearn.multiclass import OneVsRestClassifier
import numpy as np
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
def Features(x, y):
        
        logistic = LogisticRegression(C=0.01, penalty="l1",solver='liblinear', random_state=100).fit(x, y)
        model = SelectFromModel(logistic, prefit=True)
        x_new = model.transform(x)
    
        # Get back the kept features as a DataFrame with dropped columns as all 0s
        selected_features = pd.DataFrame(model.inverse_transform(x_new), 
                                        index=x.index,
                                        columns=x.columns)
       
        # Dropped columns have values of all 0s, keep other columns 
        good_columns = selected_features.columns[selected_features.var() != 0]
        print (good_columns)
        return good_columns
    
    
def Check(train_train_x,train_train_y,List):
 times = KFold(n_splits=5, shuffle=True, random_state=10)
 for a in List:
  rmse= np.sqrt(-cross_val_score(a, np.log1p(train_train_x), np.log1p(train_train_y), scoring="neg_mean_squared_error",cv=times,n_jobs=-1))
  print('The machine for cross_val_score is:',a,'The score is:',rmse.mean())
 return rmse


#index 1 = return average, index 2 = return emsambered stacking.  
def ensemble(L_bestprediction, index,L_portion = []) :
  if index == 1:
        suma = 0
        for a in L_bestprediction:
            a=+ suma
        average = suma/len(L_bestprediction)
        return average
  elif index == 2:
        c=0
        y=0
        for b in L_bestprediction:
            if y==0:
                d = b[:int(b.size*L_portion[0])]
                y+=1
                continue
            elif y>0:
                sume = 0
                L_portion[c] += sume
                d = np.hstack((d,b[int(b.size*(L_portion[c])):int(b.size*(L_portion[c]+L_portion[c+1]))]))
                print(d.shape)
                c+=1
        return d




test = pd.read_csv("../input/house-prices-advanced-regression-techniques/test.csv")
test2 = test.copy()
train = pd.read_csv("../input/house-prices-advanced-regression-techniques/train.csv")
train2=train.copy()
train.dropna(axis=0,subset=['SalePrice'],inplace=True)
train_y = train.SalePrice   #The target columns without NaN
Train_y= np.log1p(train_y)
train.drop(['Id','Street','Utilities','LowQualFinSF','3SsnPorch','PoolArea','PoolQC'],axis=1,inplace=True)
test.drop(['Id','Street','Utilities','LowQualFinSF','3SsnPorch','PoolArea','PoolQC'],axis=1,inplace=True)
train.drop(['SalePrice'],axis=1,inplace=True)  #The predictive columns





#for category part:
drop_X = train.select_dtypes(include=['object'])
drop_test_X = test.select_dtypes(include=['object'])

#fill the mising value using SimpleImputer:
SI= SimpleImputer(strategy='constant',fill_value='None')
SI_X = pd.DataFrame(SI.fit_transform(drop_X))
SI_Test_X= pd.DataFrame(SI.transform(drop_test_X))
SI_X.columns = drop_X.columns
SI_Test_X.columns = drop_test_X.columns

#encode the category data using CatBoostEncoder:
features= SI_X.columns
CE = ce.CatBoostEncoder(cols=SI_X.columns)
train_copy=pd.concat([train2.select_dtypes(include=['object']),train2['SalePrice']],axis=1)
CE.fit(train_copy[features], train_copy['SalePrice'])

a = CE.transform(SI_X[features])
b = CE.transform(SI_Test_X[features])


#for numerical part:
number_X = train.select_dtypes(exclude=['object'])
number_test_X = test.select_dtypes(exclude=['object'])
#fill the mising value using SimpleImputer:
SI_Median = SimpleImputer(strategy='constant',fill_value=0)
SI_Median_X = pd.DataFrame(SI_Median.fit_transform(number_X))
SI_Median_test_X = pd.DataFrame(SI_Median.transform(number_test_X))
SI_Median_X.columns = number_X.columns
SI_Median_test_X.columns = number_test_X.columns




#combine numerical part and categorical part:
union_x=pd.concat([a,SI_Median_X],axis=1)
UNION_TEST_X=pd.concat([b,SI_Median_test_X],axis=1)
light_train_x=pd.concat([union_x,train2['SalePrice']],axis=1)




#Split the datasize
valid_fraction = 0.2741
valid_size = int(len(union_x) * valid_fraction)
train_train = light_train_x[:-2 * valid_size]
train_valid = light_train_x[-2 * valid_size:]
feature_cols = train_train.columns.drop('SalePrice')
LIGHT_TRAIN_X = train_train[feature_cols]
LIGHT_VALID_X = train_valid[feature_cols]
train_train_y_1 = train_train['SalePrice']
train_valid_y_1 = train_valid['SalePrice']
train_train_y = np.log1p(train_train_y_1)
train_valid_y = np.log1p(train_valid_y_1)
for each in [train_train, train_valid]:
    print(each['SalePrice'].mean())




#New columns
LIGHT_TRAIN_X["TotalHouse"] = LIGHT_TRAIN_X["TotalBsmtSF"] + LIGHT_TRAIN_X["1stFlrSF"] + LIGHT_TRAIN_X["2ndFlrSF"]   
LIGHT_TRAIN_X["TotalArea"] = LIGHT_TRAIN_X["TotalBsmtSF"] + LIGHT_TRAIN_X["1stFlrSF"] + LIGHT_TRAIN_X["2ndFlrSF"] + LIGHT_TRAIN_X["GarageArea"]
LIGHT_TRAIN_X["TotalHouse"] = LIGHT_TRAIN_X["TotalBsmtSF"] + LIGHT_TRAIN_X["1stFlrSF"] + LIGHT_TRAIN_X["2ndFlrSF"] 
LIGHT_TRAIN_X["TotalArea"] = LIGHT_TRAIN_X["TotalBsmtSF"] + LIGHT_TRAIN_X["1stFlrSF"] + LIGHT_TRAIN_X["2ndFlrSF"] + LIGHT_TRAIN_X["GarageArea"]
LIGHT_TRAIN_X["+_TotalHouse_OverallQual"] = LIGHT_TRAIN_X["TotalHouse"] * LIGHT_TRAIN_X["OverallQual"] 
LIGHT_TRAIN_X["+_GrLivArea_OverallQual"] = LIGHT_TRAIN_X["GrLivArea"] * LIGHT_TRAIN_X["OverallQual"] 
LIGHT_TRAIN_X["+_oMSZoning_TotalHouse"] = LIGHT_TRAIN_X["MSZoning"] * LIGHT_TRAIN_X["TotalHouse"] 
LIGHT_TRAIN_X["+_oMSZoning_OverallQual"] = LIGHT_TRAIN_X["MSZoning"] + LIGHT_TRAIN_X["OverallQual"] 
LIGHT_TRAIN_X["+_oMSZoning_YearBuilt"] = LIGHT_TRAIN_X["MSZoning"] + LIGHT_TRAIN_X["YearBuilt"] 
LIGHT_TRAIN_X["+_oNeighborhood_TotalHouse"] = LIGHT_TRAIN_X["Neighborhood"] * LIGHT_TRAIN_X["TotalHouse"] 
LIGHT_TRAIN_X["+_oNeighborhood_OverallQual"] = LIGHT_TRAIN_X["Neighborhood"] + LIGHT_TRAIN_X["OverallQual"] 
LIGHT_TRAIN_X["+_oNeighborhood_YearBuilt"] = LIGHT_TRAIN_X["Neighborhood"] + LIGHT_TRAIN_X["YearBuilt"] 
LIGHT_TRAIN_X["+_BsmtFinSF1_OverallQual"] = LIGHT_TRAIN_X["BsmtFinSF1"] * LIGHT_TRAIN_X["OverallQual"] 
LIGHT_TRAIN_X["-_oFunctional_TotalHouse"] = LIGHT_TRAIN_X["Functional"] * LIGHT_TRAIN_X["TotalHouse"] 
LIGHT_TRAIN_X["-_oFunctional_OverallQual"] = LIGHT_TRAIN_X["Functional"] + LIGHT_TRAIN_X["OverallQual"] 
LIGHT_TRAIN_X["-_LotArea_OverallQual"] = LIGHT_TRAIN_X["LotArea"] * LIGHT_TRAIN_X["OverallQual"] 
LIGHT_TRAIN_X["-_TotalHouse_LotArea"] = LIGHT_TRAIN_X["TotalHouse"] + LIGHT_TRAIN_X["LotArea"] 
LIGHT_TRAIN_X["-_oCondition1_TotalHouse"] = LIGHT_TRAIN_X["Condition1"] * LIGHT_TRAIN_X["TotalHouse"] 
LIGHT_TRAIN_X["-_oCondition1_OverallQual"] = LIGHT_TRAIN_X["Condition1"] + LIGHT_TRAIN_X["OverallQual"] 
LIGHT_TRAIN_X["Bsmt"] = LIGHT_TRAIN_X["BsmtFinSF1"] + LIGHT_TRAIN_X["BsmtFinSF2"] + LIGHT_TRAIN_X["BsmtUnfSF"]  
LIGHT_TRAIN_X["TotalPlace"] = LIGHT_TRAIN_X["TotalBsmtSF"] + LIGHT_TRAIN_X["1stFlrSF"] + LIGHT_TRAIN_X["2ndFlrSF"] + LIGHT_TRAIN_X["GarageArea"] + LIGHT_TRAIN_X["OpenPorchSF"]+LIGHT_TRAIN_X["EnclosedPorch"]+LIGHT_TRAIN_X["ScreenPorch"]

UNION_TEST_X["TotalHouse"] = UNION_TEST_X["TotalBsmtSF"] + UNION_TEST_X["1stFlrSF"] + UNION_TEST_X["2ndFlrSF"]   
UNION_TEST_X["TotalArea"] = UNION_TEST_X["TotalBsmtSF"] + UNION_TEST_X["1stFlrSF"] + UNION_TEST_X["2ndFlrSF"] + UNION_TEST_X["GarageArea"]
UNION_TEST_X["TotalHouse"] = UNION_TEST_X["TotalBsmtSF"] + UNION_TEST_X["1stFlrSF"] + UNION_TEST_X["2ndFlrSF"] 
UNION_TEST_X["TotalArea"] = UNION_TEST_X["TotalBsmtSF"] + UNION_TEST_X["1stFlrSF"] + UNION_TEST_X["2ndFlrSF"] + UNION_TEST_X["GarageArea"]
UNION_TEST_X["+_TotalHouse_OverallQual"] = UNION_TEST_X["TotalHouse"] * UNION_TEST_X["OverallQual"] 
UNION_TEST_X["+_GrLivArea_OverallQual"] = UNION_TEST_X["GrLivArea"] * UNION_TEST_X["OverallQual"] 
UNION_TEST_X["+_oMSZoning_TotalHouse"] = UNION_TEST_X["MSZoning"] * UNION_TEST_X["TotalHouse"] 
UNION_TEST_X["+_oMSZoning_OverallQual"] = UNION_TEST_X["MSZoning"] + UNION_TEST_X["OverallQual"] 
UNION_TEST_X["+_oMSZoning_YearBuilt"] = UNION_TEST_X["MSZoning"] + UNION_TEST_X["YearBuilt"] 
UNION_TEST_X["+_oNeighborhood_TotalHouse"] = UNION_TEST_X["Neighborhood"] * UNION_TEST_X["TotalHouse"] 
UNION_TEST_X["+_oNeighborhood_OverallQual"] = UNION_TEST_X["Neighborhood"] + UNION_TEST_X["OverallQual"] 
UNION_TEST_X["+_oNeighborhood_YearBuilt"] = UNION_TEST_X["Neighborhood"] + UNION_TEST_X["YearBuilt"] 
UNION_TEST_X["+_BsmtFinSF1_OverallQual"] = UNION_TEST_X["BsmtFinSF1"] * UNION_TEST_X["OverallQual"] 
UNION_TEST_X["-_oFunctional_TotalHouse"] = UNION_TEST_X["Functional"] * UNION_TEST_X["TotalHouse"] 
UNION_TEST_X["-_oFunctional_OverallQual"] = UNION_TEST_X["Functional"] + UNION_TEST_X["OverallQual"] 
UNION_TEST_X["-_LotArea_OverallQual"] = UNION_TEST_X["LotArea"] * UNION_TEST_X["OverallQual"] 
UNION_TEST_X["-_TotalHouse_LotArea"] = UNION_TEST_X["TotalHouse"] + UNION_TEST_X["LotArea"] 
UNION_TEST_X["-_oCondition1_TotalHouse"] = UNION_TEST_X["Condition1"] * UNION_TEST_X["TotalHouse"] 
UNION_TEST_X["-_oCondition1_OverallQual"] = UNION_TEST_X["Condition1"] + UNION_TEST_X["OverallQual"] 
UNION_TEST_X["Bsmt"] = UNION_TEST_X["BsmtFinSF1"] + UNION_TEST_X["BsmtFinSF2"] + UNION_TEST_X["BsmtUnfSF"] 
 
UNION_TEST_X["TotalPlace"] = UNION_TEST_X["TotalBsmtSF"] + UNION_TEST_X["1stFlrSF"] + UNION_TEST_X["2ndFlrSF"] + UNION_TEST_X["GarageArea"] + UNION_TEST_X["OpenPorchSF"]+UNION_TEST_X["EnclosedPorch"]+UNION_TEST_X["ScreenPorch"]


LIGHT_VALID_X["TotalHouse"] = LIGHT_VALID_X["TotalBsmtSF"] + LIGHT_VALID_X["1stFlrSF"] + LIGHT_VALID_X["2ndFlrSF"]   
LIGHT_VALID_X["TotalArea"] = LIGHT_VALID_X["TotalBsmtSF"] + LIGHT_VALID_X["1stFlrSF"] + LIGHT_VALID_X["2ndFlrSF"] + LIGHT_VALID_X["GarageArea"]
LIGHT_VALID_X["TotalHouse"] = LIGHT_VALID_X["TotalBsmtSF"] + LIGHT_VALID_X["1stFlrSF"] + LIGHT_VALID_X["2ndFlrSF"] 
LIGHT_VALID_X["TotalArea"] = LIGHT_VALID_X["TotalBsmtSF"] + LIGHT_VALID_X["1stFlrSF"] + LIGHT_VALID_X["2ndFlrSF"] + LIGHT_VALID_X["GarageArea"]
LIGHT_VALID_X["+_TotalHouse_OverallQual"] = LIGHT_VALID_X["TotalHouse"] * LIGHT_VALID_X["OverallQual"] 
LIGHT_VALID_X["+_GrLivArea_OverallQual"] = LIGHT_VALID_X["GrLivArea"] * LIGHT_VALID_X["OverallQual"] 
LIGHT_VALID_X["+_oMSZoning_TotalHouse"] = LIGHT_VALID_X["MSZoning"] * LIGHT_VALID_X["TotalHouse"] 
LIGHT_VALID_X["+_oMSZoning_OverallQual"] = LIGHT_VALID_X["MSZoning"] + LIGHT_VALID_X["OverallQual"] 
LIGHT_VALID_X["+_oMSZoning_YearBuilt"] = LIGHT_VALID_X["MSZoning"] + LIGHT_VALID_X["YearBuilt"] 
LIGHT_VALID_X["+_oNeighborhood_TotalHouse"] = LIGHT_VALID_X["Neighborhood"] * LIGHT_VALID_X["TotalHouse"] 
LIGHT_VALID_X["+_oNeighborhood_OverallQual"] = LIGHT_VALID_X["Neighborhood"] + LIGHT_VALID_X["OverallQual"] 
LIGHT_VALID_X["+_oNeighborhood_YearBuilt"] = LIGHT_VALID_X["Neighborhood"] + LIGHT_VALID_X["YearBuilt"] 
LIGHT_VALID_X["+_BsmtFinSF1_OverallQual"] = LIGHT_VALID_X["BsmtFinSF1"] * LIGHT_VALID_X["OverallQual"] 
LIGHT_VALID_X["-_oFunctional_TotalHouse"] = LIGHT_VALID_X["Functional"] * LIGHT_VALID_X["TotalHouse"] 
LIGHT_VALID_X["-_oFunctional_OverallQual"] = LIGHT_VALID_X["Functional"] + LIGHT_VALID_X["OverallQual"] 
LIGHT_VALID_X["-_LotArea_OverallQual"] = LIGHT_VALID_X["LotArea"] * LIGHT_VALID_X["OverallQual"] 
LIGHT_VALID_X["-_TotalHouse_LotArea"] = LIGHT_VALID_X["TotalHouse"] + LIGHT_VALID_X["LotArea"] 
LIGHT_VALID_X["-_oCondition1_TotalHouse"] = LIGHT_VALID_X["Condition1"] * LIGHT_VALID_X["TotalHouse"] 
LIGHT_VALID_X["-_oCondition1_OverallQual"] = LIGHT_VALID_X["Condition1"] + LIGHT_VALID_X["OverallQual"] 
LIGHT_VALID_X["Bsmt"] = LIGHT_VALID_X["BsmtFinSF1"] + LIGHT_VALID_X["BsmtFinSF2"] + LIGHT_VALID_X["BsmtUnfSF"]  
LIGHT_VALID_X["TotalPlace"] = LIGHT_VALID_X["TotalBsmtSF"] + LIGHT_VALID_X["1stFlrSF"] + LIGHT_VALID_X["2ndFlrSF"] + LIGHT_VALID_X["GarageArea"] + LIGHT_VALID_X["OpenPorchSF"]+LIGHT_VALID_X["EnclosedPorch"]+LIGHT_VALID_X["ScreenPorch"]

#Regularization and remain the good columns:
#Object_Columns=Features(LIGHT_TRAIN_X,train_train_y_1)
#Object_Columns=['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig',
#       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',
#       'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',
#       'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',
#       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating',
#       'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional',
#       'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',
#       'PavedDrive', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition',
#       'LotArea', 'BsmtFinSF2', 'BsmtUnfSF', '2ndFlrSF', 'GarageYrBlt',
#       'WoodDeckSF', 'MiscVal', '+_TotalHouse_OverallQual',
#       '+_GrLivArea_OverallQual', '+_oMSZoning_TotalHouse',
#       '+_oMSZoning_OverallQual', '+_oMSZoning_YearBuilt',
#       '+_oNeighborhood_TotalHouse', '+_oNeighborhood_OverallQual',
#       '+_oNeighborhood_YearBuilt', '+_BsmtFinSF1_OverallQual',
#       '-_oFunctional_TotalHouse', '-_oFunctional_OverallQual',
#       '-_LotArea_OverallQual', '-_TotalHouse_LotArea',
#       '-_oCondition1_TotalHouse', '-_oCondition1_OverallQual', 'TotalPlace']
#remained_train_X = LIGHT_TRAIN_X[Object_Columns]
#remained_valid_X = LIGHT_VALID_X[Object_Columns]
#remained_test_X = UNION_TEST_X[Object_Columns] 

#log the columns that has positive skewness and encode them with get_dummies
Numeric= LIGHT_TRAIN_X.select_dtypes(exclude=['object'])
for a in Numeric.columns:
    if abs(LIGHT_TRAIN_X[a].skew(axis=0))>=1 and a in Numeric.columns:
        LIGHT_TRAIN_X[a]=np.log1p(LIGHT_TRAIN_X[a])
        pd.get_dummies(LIGHT_TRAIN_X[a])
        LIGHT_VALID_X[a]=np.log1p(LIGHT_VALID_X[a])
        pd.get_dummies(LIGHT_VALID_X[a])
    if abs(UNION_TEST_X[a].skew(axis=0))>=1 and a in Numeric.columns:
        UNION_TEST_X[a]=np.log1p(UNION_TEST_X[a])
        pd.get_dummies(UNION_TEST_X[a])
    if abs(LIGHT_TRAIN_X[a].skew(axis=0))>=1 and a not in Numeric.columns:
        LIGHT_TRAIN_X[a]=np.log1p(LIGHT_TRAIN_X[a])
        pd.get_dummies(LIGHT_TRAIN_X[a])
        LIGHT_VALID_X[a]=np.log1p(LIGHT_VALID_X[a])
        pd.get_dummies(LIGHT_VALID_X[a])
    if abs(UNION_TEST_X[a].skew(axis=0))>=1 and a in Numeric.columns:
        UNION_TEST_X[a]=np.log1p(UNION_TEST_X[a])
        pd.get_dummies(UNION_TEST_X[a])
    else:
        pd.get_dummies(LIGHT_TRAIN_X[a])
        pd.get_dummies(LIGHT_VALID_X[a])
        pd.get_dummies(UNION_TEST_X[a])
#preprocessing the data to have all datas in the same standard, also known as normalization
scalar = StandardScaler()
standard_x =  pd.DataFrame(data=scalar.fit(LIGHT_TRAIN_X).transform(LIGHT_TRAIN_X), columns=LIGHT_TRAIN_X.columns[:])
standard_valid_x=pd.DataFrame(data=scalar.fit(LIGHT_VALID_X).transform(LIGHT_VALID_X), columns=LIGHT_VALID_X.columns[:])
standard_test_x = pd.DataFrame(data=scalar.fit(UNION_TEST_X).transform(UNION_TEST_X), columns=UNION_TEST_X.columns[:])


#PCA
pca = PCA(n_components=0.965)
Remained_train_X = pca.fit_transform(standard_x)
Remained_train_X = pd.DataFrame(np.reshape(Remained_train_X,(660,int(Remained_train_X.size/660))),columns=LIGHT_TRAIN_X.columns[:int(Remained_train_X.size/660)])
Remained_valid_X = pca.transform(standard_valid_x)
Remained_valid_X = pd.DataFrame(np.reshape(Remained_valid_X,(800,int(Remained_valid_X.size/800))),columns=LIGHT_TRAIN_X.columns[:int(Remained_train_X.size/660)])
Remained_test_X = pca.transform(standard_test_x)
Remained_test_X = pd.DataFrame(data=np.reshape(Remained_test_X,(1459,int(Remained_test_X.size/1459))),columns=LIGHT_TRAIN_X.columns[:int(Remained_train_X.size/660)])

#Light

prepare = LGBMRegressor(metric='mae',num_leaves= 60,objective='regression', learning_rate=0.001, n_estimators=5000)
prepare.fit(Remained_train_X,train_train_y,eval_set=[(Remained_valid_X,train_valid_y)], early_stopping_rounds=1000)
bestprediction4 = prepare.predict(Remained_test_X)

#XGBOOST
my_model = XGBRegressor(n_estimators=5000,objective ='reg:squarederror', learning_rate=0.001)
my_model.fit(Remained_train_X, train_train_y,early_stopping_rounds=1000,eval_set=[(Remained_valid_X, train_valid_y)], verbose=False)
bestprediction3=my_model.predict(Remained_test_X)
#Using Linear Regression model:
bestm1=LinearRegression()
bestm1.fit(Remained_train_X,train_train_y)
bestprediction1=bestm1.predict(Remained_test_X)


#RandomTreeRegressor
bestm2 = RandomForestRegressor(random_state=5)
bestm2.fit(Remained_train_X,train_train_y)
bestprediction2=bestm2.predict(Remained_test_X)

List = [prepare,my_model,bestm1,bestm2]
#Check(Remained_train_X,train_train_y_1,List)


#Using Stack to combine each portion of estimator's predition together 
List=[bestprediction4,bestprediction2,bestprediction1]  # List of the model to pass to the function
Portion= [0.7,0.15,0.15]   #List of proportion for the List of the model, must add up to 1. for this example, bestprediction4 will have 0.7 size.
c= ensemble(List,2,Portion) #The index 1 will return the average point of each prediction, index 2 will return one prediction that mix different preditions with their associated proportion together.
bestprediction=np.expm1(c)

predictionframe = pd.DataFrame({'Id':test2.Id,
                       'SalePrice': bestprediction})
predictionframe.to_csv('submission.csv', index=False)
