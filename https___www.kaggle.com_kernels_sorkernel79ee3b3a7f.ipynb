{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#!pip install category_encoders\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model  import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\nfrom lightgbm import LGBMRegressor \nimport category_encoders as ce\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.multiclass import OneVsRestClassifier\nimport numpy as np\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\ndef Features(x, y):\n        \n        logistic = LogisticRegression(C=0.35, penalty=\"l1\",solver='liblinear', random_state=5).fit(x, y)\n        model = SelectFromModel(logistic, prefit=True)\n        x_new = model.transform(x)\n    \n        # Get back the kept features as a DataFrame with dropped columns as all 0s\n        selected_features = pd.DataFrame(model.inverse_transform(x_new), \n                                        index=x.index,\n                                        columns=x.columns)\n       \n        # Dropped columns have values of all 0s, keep other columns \n        good_columns = selected_features.columns[selected_features.var() != 0]\n        print (good_columns)\n        return good_columns\n    \n    \ndef Check(train_train_x,train_train_y,List):\n times = KFold(n_splits=5, shuffle=True, random_state=10)\n for a in List:\n  rmse= np.sqrt(-cross_val_score(a, np.log1p(train_train_x), np.log1p(train_train_y), scoring=\"neg_mean_squared_error\",cv=times,n_jobs=-1))\n  print('The machine for cross_val_score is:',a,'The score is:',rmse.mean())\n return rmse\n\n\n#index 1 = return average, index 2 = return emsambered stacking.  \ndef ensemble(L_bestprediction, index,L_portion = []) :\n  if index == 1:\n        suma = 0\n        for a in L_bestprediction:\n            suma += a\n        average = suma/len(L_bestprediction)\n        return average\n  elif index == 2:\n        c=0\n        y=0\n        for b in L_bestprediction:\n            if y==0:\n                d = b[:int(b.size*L_portion[0])]\n                y+=1\n                continue\n            elif y>0:\n                sume = 0\n                L_portion[c] += sume\n                d = np.hstack((d,b[int(b.size*(L_portion[c])):int(b.size*(L_portion[c]+L_portion[c+1]))]))\n                print(d.shape)\n                c+=1\n        return d\n\n    \n#exclude any outlier in the numerical part which helps to improve the accuracy of data.\ndef outlier(x):\n    y=np.array(x,dtype=np.int)\n    g=np.array(x,dtype=np.int)\n    x=pd.DataFrame(x,dtype=np.int)\n    Q1 = x.quantile(0.25)\n    Q2 = x.quantile(0.5)\n    Q3 = x.quantile(0.75)\n    IQR = float(Q3 - Q1)\n    c=[]\n    for i in range(len(x)):\n     y[i] = (y[i] < (Q1 - 1.5 * IQR)) | (y[i] > (Q3 + 1.5 * IQR))\n     if y[i] == True:\n        g[i]= int(Q2)\n    g = pd.DataFrame(g,dtype=np.int)\n    return g\n\n\ntest = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/test.csv\")\ntest2 = test.copy()\ntrain = pd.read_csv(\"../input/house-prices-advanced-regression-techniques/train.csv\")\ntrain2=train.copy()\ntrain.dropna(axis=0,subset=['SalePrice'],inplace=True)\ntrain_y = train.SalePrice   #The target columns without NaN\nTrain_y= np.log1p(train_y)\ntrain.drop(['Id','Street','Utilities','LowQualFinSF','3SsnPorch','PoolArea','PoolQC'],axis=1,inplace=True)\ntest.drop(['Id','Street','Utilities','LowQualFinSF','3SsnPorch','PoolArea','PoolQC'],axis=1,inplace=True)\ntrain.drop(['SalePrice'],axis=1,inplace=True)  #The predictive columns\n\n\n#for category part:\ndrop_X = train.select_dtypes(include=['object'])\ndrop_test_X = test.select_dtypes(include=['object'])\n\n\n#fill the mising value using SimpleImputer:\nSI= SimpleImputer(strategy='constant',fill_value='None')\nSI_X = pd.DataFrame(SI.fit_transform(drop_X))\nSI_Test_X= pd.DataFrame(SI.fit_transform(drop_test_X))\nSI_X.columns = drop_X.columns\nSI_Test_X.columns = drop_test_X.columns\n\n\n\n#for numerical part:\nnumber_X = train.select_dtypes(exclude=['object'])\nnumber_test_X = test.select_dtypes(exclude=['object'])\n#fill the mising value using SimpleImputer:\nSI_Median = SimpleImputer(strategy='constant',fill_value=0)\nSI_Median_X = pd.DataFrame(SI_Median.fit_transform(number_X))\nSI_Median_test_X = pd.DataFrame(SI_Median.transform(number_test_X))\nSI_Median_X.columns = number_X.columns\nSI_Median_test_X.columns = number_test_X.columns\n\n#Exclude Outlier:\n'''\nfor i in SI_Median_X.columns:\n    SI_Median_X[i]=pd.DataFrame(outlier(SI_Median_X[i]))\n'''\n#combine numerical part and categorical part:\nunion_x=pd.concat([SI_X,SI_Median_X],axis=1)\nUNION_TEST_X=pd.concat([SI_Test_X,SI_Median_test_X],axis=1)\nLIGHT_TRAIN_X=pd.concat([union_x,train2['SalePrice']],axis=1)\n\n\n#New columns\nLIGHT_TRAIN_X[\"TotalHouse\"] = LIGHT_TRAIN_X[\"TotalBsmtSF\"].astype(int) + LIGHT_TRAIN_X[\"1stFlrSF\"].astype(int) + LIGHT_TRAIN_X[\"2ndFlrSF\"].astype(int)   \nLIGHT_TRAIN_X[\"TotalArea\"] = LIGHT_TRAIN_X[\"TotalBsmtSF\"] + LIGHT_TRAIN_X[\"1stFlrSF\"] + LIGHT_TRAIN_X[\"2ndFlrSF\"] + LIGHT_TRAIN_X[\"GarageArea\"]\nLIGHT_TRAIN_X[\"+_TotalHouse_OverallQual\"] = LIGHT_TRAIN_X[\"TotalHouse\"] * LIGHT_TRAIN_X[\"OverallQual\"] \nLIGHT_TRAIN_X[\"+_GrLivArea_OverallQual\"] = LIGHT_TRAIN_X[\"GrLivArea\"] * LIGHT_TRAIN_X[\"OverallQual\"] \nLIGHT_TRAIN_X[\"+_oMSZoning_TotalHouse\"] = LIGHT_TRAIN_X[\"MSZoning\"] * LIGHT_TRAIN_X[\"TotalHouse\"].astype(int)\nLIGHT_TRAIN_X[\"+_oMSZoning_OverallQual\"] = LIGHT_TRAIN_X[\"MSZoning\"] + LIGHT_TRAIN_X[\"OverallQual\"].astype(str) \nLIGHT_TRAIN_X[\"+_oMSZoning_YearBuilt\"] = LIGHT_TRAIN_X[\"MSZoning\"] + LIGHT_TRAIN_X[\"YearBuilt\"].astype(str) \nLIGHT_TRAIN_X[\"+_oNeighborhood_TotalHouse\"] = LIGHT_TRAIN_X[\"Neighborhood\"] * LIGHT_TRAIN_X[\"TotalHouse\"] \nLIGHT_TRAIN_X[\"+_oNeighborhood_OverallQual\"] = LIGHT_TRAIN_X[\"Neighborhood\"] + LIGHT_TRAIN_X[\"OverallQual\"].astype(str)  \nLIGHT_TRAIN_X[\"+_oNeighborhood_YearBuilt\"] = LIGHT_TRAIN_X[\"Neighborhood\"] + LIGHT_TRAIN_X[\"YearBuilt\"].astype(str)  \nLIGHT_TRAIN_X[\"+_BsmtFinSF1_OverallQual\"] = LIGHT_TRAIN_X[\"BsmtFinSF1\"] * LIGHT_TRAIN_X[\"OverallQual\"] \nLIGHT_TRAIN_X[\"-_oFunctional_TotalHouse\"] = LIGHT_TRAIN_X[\"Functional\"] * LIGHT_TRAIN_X[\"TotalHouse\"] \nLIGHT_TRAIN_X[\"-_oFunctional_OverallQual\"] = LIGHT_TRAIN_X[\"Functional\"] + LIGHT_TRAIN_X[\"OverallQual\"].astype(str)  \nLIGHT_TRAIN_X[\"-_LotArea_OverallQual\"] = LIGHT_TRAIN_X[\"LotArea\"] * LIGHT_TRAIN_X[\"OverallQual\"].astype(int) \nLIGHT_TRAIN_X[\"-_TotalHouse_LotArea\"] = LIGHT_TRAIN_X[\"TotalHouse\"] + LIGHT_TRAIN_X[\"LotArea\"] \nLIGHT_TRAIN_X[\"-_oCondition1_TotalHouse\"] = LIGHT_TRAIN_X[\"Condition1\"] * LIGHT_TRAIN_X[\"TotalHouse\"] \nLIGHT_TRAIN_X[\"-_oCondition1_OverallQual\"] = LIGHT_TRAIN_X[\"Condition1\"] + LIGHT_TRAIN_X[\"OverallQual\"].astype(str)  \nLIGHT_TRAIN_X[\"Bsmt\"] = LIGHT_TRAIN_X[\"BsmtFinSF1\"] + LIGHT_TRAIN_X[\"BsmtFinSF2\"] + LIGHT_TRAIN_X[\"BsmtUnfSF\"]  \nLIGHT_TRAIN_X[\"TotalPlace\"] = LIGHT_TRAIN_X[\"TotalBsmtSF\"] + LIGHT_TRAIN_X[\"1stFlrSF\"] + LIGHT_TRAIN_X[\"2ndFlrSF\"] + LIGHT_TRAIN_X[\"GarageArea\"] + LIGHT_TRAIN_X[\"OpenPorchSF\"]+LIGHT_TRAIN_X[\"EnclosedPorch\"]+LIGHT_TRAIN_X[\"ScreenPorch\"]\nLIGHT_TRAIN_X.drop(columns=[\"TotalBsmtSF\",\"1stFlrSF\",\"2ndFlrSF\",\"GarageArea\",\"OverallQual\",\"GrLivArea\",\"MSZoning\",\"YearBuilt\",\"BsmtFinSF1\",\"Neighborhood\",\"LotArea\",\"Condition1\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"OpenPorchSF\",\"EnclosedPorch\",\"ScreenPorch\"])\n\nUNION_TEST_X[\"TotalHouse\"] = UNION_TEST_X[\"TotalBsmtSF\"].astype(int) + UNION_TEST_X[\"1stFlrSF\"].astype(int) + UNION_TEST_X[\"2ndFlrSF\"].astype(int) \nUNION_TEST_X[\"TotalArea\"] = UNION_TEST_X[\"TotalBsmtSF\"] + UNION_TEST_X[\"1stFlrSF\"] + UNION_TEST_X[\"2ndFlrSF\"] + UNION_TEST_X[\"GarageArea\"]\nUNION_TEST_X[\"+_TotalHouse_OverallQual\"] = UNION_TEST_X[\"TotalHouse\"] * UNION_TEST_X[\"OverallQual\"] \nUNION_TEST_X[\"+_GrLivArea_OverallQual\"] = UNION_TEST_X[\"GrLivArea\"] * UNION_TEST_X[\"OverallQual\"] \nUNION_TEST_X[\"+_oMSZoning_TotalHouse\"] = UNION_TEST_X[\"MSZoning\"] * UNION_TEST_X[\"TotalHouse\"].astype(int) \nUNION_TEST_X[\"+_oMSZoning_OverallQual\"] = UNION_TEST_X[\"MSZoning\"] + UNION_TEST_X[\"OverallQual\"].astype(str) \nUNION_TEST_X[\"+_oMSZoning_YearBuilt\"] = UNION_TEST_X[\"MSZoning\"] + UNION_TEST_X[\"YearBuilt\"].astype(str)  \nUNION_TEST_X[\"+_oNeighborhood_TotalHouse\"] = UNION_TEST_X[\"Neighborhood\"] * UNION_TEST_X[\"TotalHouse\"] \nUNION_TEST_X[\"+_oNeighborhood_OverallQual\"] = UNION_TEST_X[\"Neighborhood\"] + UNION_TEST_X[\"OverallQual\"].astype(str)   \nUNION_TEST_X[\"+_oNeighborhood_YearBuilt\"] = UNION_TEST_X[\"Neighborhood\"] + UNION_TEST_X[\"YearBuilt\"].astype(str)   \nUNION_TEST_X[\"+_BsmtFinSF1_OverallQual\"] = UNION_TEST_X[\"BsmtFinSF1\"] * UNION_TEST_X[\"OverallQual\"] \nUNION_TEST_X[\"-_oFunctional_TotalHouse\"] = UNION_TEST_X[\"Functional\"] * UNION_TEST_X[\"TotalHouse\"] \nUNION_TEST_X[\"-_oFunctional_OverallQual\"] = UNION_TEST_X[\"Functional\"] + UNION_TEST_X[\"OverallQual\"].astype(str)   \nUNION_TEST_X[\"-_LotArea_OverallQual\"] = UNION_TEST_X[\"LotArea\"] * UNION_TEST_X[\"OverallQual\"].astype(int) \nUNION_TEST_X[\"-_TotalHouse_LotArea\"] = UNION_TEST_X[\"TotalHouse\"] + UNION_TEST_X[\"LotArea\"] \nUNION_TEST_X[\"-_oCondition1_TotalHouse\"] = UNION_TEST_X[\"Condition1\"] * UNION_TEST_X[\"TotalHouse\"] \nUNION_TEST_X[\"-_oCondition1_OverallQual\"] = UNION_TEST_X[\"Condition1\"] + UNION_TEST_X[\"OverallQual\"].astype(str) \nUNION_TEST_X[\"Bsmt\"] = UNION_TEST_X[\"BsmtFinSF1\"] + UNION_TEST_X[\"BsmtFinSF2\"] + UNION_TEST_X[\"BsmtUnfSF\"] \nUNION_TEST_X[\"TotalPlace\"] = UNION_TEST_X[\"TotalBsmtSF\"] + UNION_TEST_X[\"1stFlrSF\"] + UNION_TEST_X[\"2ndFlrSF\"] + UNION_TEST_X[\"GarageArea\"] + UNION_TEST_X[\"OpenPorchSF\"]+UNION_TEST_X[\"EnclosedPorch\"]+UNION_TEST_X[\"ScreenPorch\"]\nUNION_TEST_X.drop(columns=[\"TotalBsmtSF\",\"1stFlrSF\",\"2ndFlrSF\",\"GarageArea\",\"OverallQual\",\"GrLivArea\",\"MSZoning\",\"YearBuilt\",\"BsmtFinSF1\",\"Neighborhood\",\"LotArea\",\"Condition1\",\"BsmtFinSF2\",\"BsmtUnfSF\",\"OpenPorchSF\",\"EnclosedPorch\",\"ScreenPorch\"])\n#encode categorical columns with CatEncoder and log the columns that has positive skewness:\n\nNumeric= UNION_TEST_X.select_dtypes(exclude=['object'])\ncategorical = UNION_TEST_X.select_dtypes(include=['object']).columns\nCE = ce.CatBoostEncoder(cols=categorical)\nCE.fit(LIGHT_TRAIN_X[categorical], LIGHT_TRAIN_X['SalePrice'])\nLIGHT_TRAIN_X[categorical] = CE.transform(LIGHT_TRAIN_X[categorical])\nUNION_TEST_X[categorical] = CE.transform(UNION_TEST_X[categorical])\nfor a in UNION_TEST_X.columns:\n    if a in Numeric.columns and abs(LIGHT_TRAIN_X[a].skew(axis=0))>=1:\n        LIGHT_TRAIN_X[a]=np.log1p(LIGHT_TRAIN_X[a])\n    elif a not in Numeric.columns:\n            if abs(LIGHT_TRAIN_X[a].skew(axis=0))>=1:\n                LIGHT_TRAIN_X[a]=np.log1p(LIGHT_TRAIN_X[a])\nfor a in UNION_TEST_X.columns:\n    if a in Numeric.columns and abs(UNION_TEST_X[a].skew(axis=0))>=1 :\n        UNION_TEST_X[a]=np.log1p(UNION_TEST_X[a])\n    elif a not in Numeric.columns:\n            if abs(UNION_TEST_X[a].skew(axis=0))>=1:\n                UNION_TEST_X[a]=np.log1p(UNION_TEST_X[a])\n\n\n#Split the datasize\nvalid_fraction = 0.2741\nvalid_size = int(len(union_x) * valid_fraction)\ntrain_train = LIGHT_TRAIN_X[:-2 * valid_size]\ntrain_valid = LIGHT_TRAIN_X[-2 * valid_size:]\nfeature_cols = train_train.columns.drop('SalePrice')\nLIGHT_TRAIN_X = train_train[feature_cols]\nLIGHT_VALID_X = train_valid[feature_cols]\ntrain_train_y_1 = train_train['SalePrice']\ntrain_valid_y_1 = train_valid['SalePrice']\ntrain_train_y = np.log1p(train_train_y_1)\ntrain_valid_y = np.log1p(train_valid_y_1)\nfor each in [train_train, train_valid]:\n    print(each['SalePrice'].mean())\n\n\n\n\n#Regularization and remain the good columns:\n#Object_Columns=Features(LIGHT_TRAIN_X,train_train_y_1)\n'''\nObject_Columns=['MSZoning', 'Alley', 'LotShape', 'LandContour', 'LotConfig',\n       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',\n       'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd',\n       'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating',\n       'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional',\n       'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n       'PavedDrive', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition',\n       'LotArea', 'BsmtFinSF2', 'BsmtUnfSF', '2ndFlrSF', 'GarageYrBlt',\n       'WoodDeckSF', 'MiscVal', '+_TotalHouse_OverallQual',\n       '+_GrLivArea_OverallQual', '+_oMSZoning_TotalHouse',\n       '+_oMSZoning_OverallQual', '+_oMSZoning_YearBuilt',\n       '+_oNeighborhood_TotalHouse', '+_oNeighborhood_OverallQual',\n       '+_oNeighborhood_YearBuilt', '+_BsmtFinSF1_OverallQual',\n       '-_oFunctional_TotalHouse', '-_oFunctional_OverallQual',\n       '-_LotArea_OverallQual', '-_TotalHouse_LotArea',\n       '-_oCondition1_TotalHouse', '-_oCondition1_OverallQual', 'TotalPlace']\nLIGHT_TRAIN_X = LIGHT_TRAIN_X[Object_Columns]\nLIGHT_VALID_X = LIGHT_VALID_X[Object_Columns]\nUNION_TEST_X = UNION_TEST_X[Object_Columns] \n'''\n#preprocessing the data to have all datas in the same standard, also known as normalization\nscalar = StandardScaler()\nstandard_x =  pd.DataFrame(data=scalar.fit(LIGHT_TRAIN_X).transform(LIGHT_TRAIN_X), columns=LIGHT_TRAIN_X.columns[:])\nstandard_valid_x=pd.DataFrame(data=scalar.fit(LIGHT_VALID_X).transform(LIGHT_VALID_X), columns=LIGHT_VALID_X.columns[:])\nstandard_test_x = pd.DataFrame(data=scalar.fit(UNION_TEST_X).transform(UNION_TEST_X), columns=UNION_TEST_X.columns[:])\n\n#PCA\npca = PCA(n_components= 0.965)\nRemained_train_X = pca.fit_transform(standard_x)\nRemained_train_X = pd.DataFrame(np.reshape(Remained_train_X,(660,int(Remained_train_X.size/660))),columns=LIGHT_TRAIN_X.columns[:int(Remained_train_X.size/660)])\nRemained_valid_X = pca.transform(standard_valid_x)\nRemained_valid_X = pd.DataFrame(np.reshape(Remained_valid_X,(800,int(Remained_valid_X.size/800))),columns=LIGHT_TRAIN_X.columns[:int(Remained_valid_X.size/800)])\nRemained_test_X = pca.transform(standard_test_x)\nRemained_test_X = pd.DataFrame(data=np.reshape(Remained_test_X,(1459,int(Remained_test_X.size/1459))),columns=LIGHT_TRAIN_X.columns[:int(Remained_test_X.size/1459)])\n\n#Light\nprepare_new = LGBMRegressor(metric='mae',num_leaves= 60,objective='regression', learning_rate=0.01, n_estimators=1000)\nprepare = LGBMRegressor(metric='mae',num_leaves= 60,objective='regression', learning_rate=0.01, n_estimators=20000)\nprepare.fit(LIGHT_TRAIN_X,train_train_y,eval_set=[(LIGHT_VALID_X,train_valid_y)], early_stopping_rounds=100)\nbestprediction4 = prepare.predict(UNION_TEST_X)\n\n#XGBOOST\nmy_model_new = XGBRegressor(n_estimators=1000,objective ='reg:squarederror', learning_rate=0.01)\nmy_model = XGBRegressor(n_estimators=20000,objective ='reg:squarederror', learning_rate=0.01)\nmy_model.fit(Remained_train_X, train_train_y,early_stopping_rounds=100,eval_set=[(Remained_valid_X, train_valid_y)], verbose=False)\nbestprediction3=my_model.predict(Remained_test_X)\n\n\n#Using Linear Regression model:\nbestm1=LinearRegression()\nbestm1.fit(Remained_train_X,train_train_y)\nbestprediction1=bestm1.predict(Remained_test_X)\n\n\n#RandomTreeRegressor\nbestm2 = RandomForestRegressor(random_state=5)\nbestm2.fit(Remained_train_X,train_train_y)\nbestprediction2=bestm2.predict(Remained_test_X)\n#https://towardsdatascience.com/how-to-perform-lasso-and-ridge-regression-in-python-3b3b75541ad8\n#Ridge\nfrom sklearn.linear_model import Ridge\nridge=Ridge()\nparameters={'alpha':[1e-15,1e-10,1e-8,1e-4,1e-3,1e-2,1,5,10,20]}\nridge_regressor=GridSearchCV(ridge,parameters,scoring=\"neg_mean_squared_error\",cv=5)\nridge_regressor.fit(Remained_train_X,train_train_y)\nbestprediction5=ridge_regressor.predict(Remained_test_X)\n#Lasso\nfrom sklearn.linear_model import Lasso\nlasso=Lasso()\nlasso_regressor=GridSearchCV(ridge,parameters,scoring=\"neg_mean_squared_error\",cv=5)\nlasso_regressor.fit(Remained_train_X,train_train_y)\nbestprediction6=lasso_regressor.predict(Remained_test_X)\n\nList = [prepare_new,my_model_new,bestm1,bestm2,ridge_regressor,lasso_regressor]\n#Check(np.expm1(Remained_train_X),train_train_y_1,List)\n\n\n#Using Stack to combine each portion of estimator's predition together \nList1=[bestprediction5,bestprediction3,bestprediction2,bestprediction6,bestprediction4,bestprediction1]  # List of the model to pass to the function\nPortion= [0.2,0.15,0.15,0.5]   #List of proportion for the xList of the model, must add up to 1. for this example, bestprediction4 will have 0.7 size.\nc= ensemble(List1,1)\nbestprediction=np.expm1(c)\n\npredictionframe = pd.DataFrame({'Id':test2.Id,\n                       'SalePrice': bestprediction})\npredictionframe.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[{"output_type":"stream","text":"182036.72424242424\n180000.885\n[1]\tvalid_0's l1: 0.295862\nTraining until validation scores don't improve for 100 rounds\n[2]\tvalid_0's l1: 0.293382\n[3]\tvalid_0's l1: 0.290818\n[4]\tvalid_0's l1: 0.288338\n[5]\tvalid_0's l1: 0.285821\n[6]\tvalid_0's l1: 0.283357\n[7]\tvalid_0's l1: 0.28095\n[8]\tvalid_0's l1: 0.278528\n[9]\tvalid_0's l1: 0.276122\n[10]\tvalid_0's l1: 0.273819\n[11]\tvalid_0's l1: 0.271472\n[12]\tvalid_0's l1: 0.269159\n[13]\tvalid_0's l1: 0.266894\n[14]\tvalid_0's l1: 0.264701\n[15]\tvalid_0's l1: 0.262447\n[16]\tvalid_0's l1: 0.260222\n[17]\tvalid_0's l1: 0.258028\n[18]\tvalid_0's l1: 0.255845\n[19]\tvalid_0's l1: 0.25375\n[20]\tvalid_0's l1: 0.251624\n[21]\tvalid_0's l1: 0.249586\n[22]\tvalid_0's l1: 0.247507\n[23]\tvalid_0's l1: 0.245501\n[24]\tvalid_0's l1: 0.243463\n[25]\tvalid_0's l1: 0.241489\n[26]\tvalid_0's l1: 0.239499\n[27]\tvalid_0's l1: 0.237567\n[28]\tvalid_0's l1: 0.235679\n[29]\tvalid_0's l1: 0.233778\n[30]\tvalid_0's l1: 0.231839\n[31]\tvalid_0's l1: 0.229976\n[32]\tvalid_0's l1: 0.228142\n[33]\tvalid_0's l1: 0.226395\n[34]\tvalid_0's l1: 0.224579\n[35]\tvalid_0's l1: 0.222839\n[36]\tvalid_0's l1: 0.221115\n[37]\tvalid_0's l1: 0.219399\n[38]\tvalid_0's l1: 0.21771\n[39]\tvalid_0's l1: 0.215986\n[40]\tvalid_0's l1: 0.214306\n[41]\tvalid_0's l1: 0.212659\n[42]\tvalid_0's l1: 0.211056\n[43]\tvalid_0's l1: 0.20944\n[44]\tvalid_0's l1: 0.207853\n[45]\tvalid_0's l1: 0.206241\n[46]\tvalid_0's l1: 0.204661\n[47]\tvalid_0's l1: 0.203158\n[48]\tvalid_0's l1: 0.201608\n[49]\tvalid_0's l1: 0.200049\n[50]\tvalid_0's l1: 0.198485\n[51]\tvalid_0's l1: 0.196984\n[52]\tvalid_0's l1: 0.195463\n[53]\tvalid_0's l1: 0.19406\n[54]\tvalid_0's l1: 0.192602\n[55]\tvalid_0's l1: 0.191174\n[56]\tvalid_0's l1: 0.189809\n[57]\tvalid_0's l1: 0.188409\n[58]\tvalid_0's l1: 0.187083\n[59]\tvalid_0's l1: 0.185733\n[60]\tvalid_0's l1: 0.184416\n[61]\tvalid_0's l1: 0.183113\n[62]\tvalid_0's l1: 0.181826\n[63]\tvalid_0's l1: 0.180548\n[64]\tvalid_0's l1: 0.179316\n[65]\tvalid_0's l1: 0.178048\n[66]\tvalid_0's l1: 0.176825\n[67]\tvalid_0's l1: 0.175654\n[68]\tvalid_0's l1: 0.174405\n[69]\tvalid_0's l1: 0.173234\n[70]\tvalid_0's l1: 0.172078\n[71]\tvalid_0's l1: 0.170973\n[72]\tvalid_0's l1: 0.169796\n[73]\tvalid_0's l1: 0.168684\n[74]\tvalid_0's l1: 0.167572\n[75]\tvalid_0's l1: 0.166454\n[76]\tvalid_0's l1: 0.165334\n[77]\tvalid_0's l1: 0.164285\n[78]\tvalid_0's l1: 0.163164\n[79]\tvalid_0's l1: 0.162141\n[80]\tvalid_0's l1: 0.161047\n[81]\tvalid_0's l1: 0.160023\n[82]\tvalid_0's l1: 0.158996\n[83]\tvalid_0's l1: 0.157974\n[84]\tvalid_0's l1: 0.15698\n[85]\tvalid_0's l1: 0.155971\n[86]\tvalid_0's l1: 0.155015\n[87]\tvalid_0's l1: 0.154055\n[88]\tvalid_0's l1: 0.153112\n[89]\tvalid_0's l1: 0.152126\n[90]\tvalid_0's l1: 0.151223\n[91]\tvalid_0's l1: 0.150278\n[92]\tvalid_0's l1: 0.149336\n[93]\tvalid_0's l1: 0.148409\n[94]\tvalid_0's l1: 0.147555\n[95]\tvalid_0's l1: 0.146696\n[96]\tvalid_0's l1: 0.145774\n[97]\tvalid_0's l1: 0.144951\n[98]\tvalid_0's l1: 0.144088\n[99]\tvalid_0's l1: 0.143265\n[100]\tvalid_0's l1: 0.142434\n[101]\tvalid_0's l1: 0.141607\n[102]\tvalid_0's l1: 0.140816\n[103]\tvalid_0's l1: 0.14004\n[104]\tvalid_0's l1: 0.139235\n[105]\tvalid_0's l1: 0.138507\n[106]\tvalid_0's l1: 0.137768\n[107]\tvalid_0's l1: 0.137007\n[108]\tvalid_0's l1: 0.136303\n[109]\tvalid_0's l1: 0.135554\n[110]\tvalid_0's l1: 0.134847\n[111]\tvalid_0's l1: 0.134094\n[112]\tvalid_0's l1: 0.133438\n[113]\tvalid_0's l1: 0.132786\n[114]\tvalid_0's l1: 0.132101\n[115]\tvalid_0's l1: 0.131489\n[116]\tvalid_0's l1: 0.130846\n[117]\tvalid_0's l1: 0.130232\n[118]\tvalid_0's l1: 0.129621\n[119]\tvalid_0's l1: 0.128965\n[120]\tvalid_0's l1: 0.128348\n[121]\tvalid_0's l1: 0.127732\n[122]\tvalid_0's l1: 0.127186\n[123]\tvalid_0's l1: 0.126578\n[124]\tvalid_0's l1: 0.125969\n[125]\tvalid_0's l1: 0.125408\n[126]\tvalid_0's l1: 0.124836\n[127]\tvalid_0's l1: 0.124258\n[128]\tvalid_0's l1: 0.123688\n[129]\tvalid_0's l1: 0.123192\n[130]\tvalid_0's l1: 0.122646\n[131]\tvalid_0's l1: 0.122151\n[132]\tvalid_0's l1: 0.121681\n[133]\tvalid_0's l1: 0.121145\n[134]\tvalid_0's l1: 0.120618\n[135]\tvalid_0's l1: 0.120116\n[136]\tvalid_0's l1: 0.119619\n[137]\tvalid_0's l1: 0.11917\n[138]\tvalid_0's l1: 0.118675\n[139]\tvalid_0's l1: 0.118195\n[140]\tvalid_0's l1: 0.117727\n[141]\tvalid_0's l1: 0.117271\n[142]\tvalid_0's l1: 0.116809\n[143]\tvalid_0's l1: 0.116367\n[144]\tvalid_0's l1: 0.115929\n[145]\tvalid_0's l1: 0.115484\n[146]\tvalid_0's l1: 0.115042\n[147]\tvalid_0's l1: 0.114626\n[148]\tvalid_0's l1: 0.114231\n[149]\tvalid_0's l1: 0.113829\n[150]\tvalid_0's l1: 0.113416\n[151]\tvalid_0's l1: 0.113022\n[152]\tvalid_0's l1: 0.112679\n[153]\tvalid_0's l1: 0.112326\n[154]\tvalid_0's l1: 0.111954\n[155]\tvalid_0's l1: 0.111604\n[156]\tvalid_0's l1: 0.11124\n[157]\tvalid_0's l1: 0.110927\n[158]\tvalid_0's l1: 0.110587\n[159]\tvalid_0's l1: 0.110279\n[160]\tvalid_0's l1: 0.109954\n[161]\tvalid_0's l1: 0.109639\n[162]\tvalid_0's l1: 0.10933\n[163]\tvalid_0's l1: 0.109021\n[164]\tvalid_0's l1: 0.108718\n[165]\tvalid_0's l1: 0.108397\n[166]\tvalid_0's l1: 0.108124\n[167]\tvalid_0's l1: 0.107822\n[168]\tvalid_0's l1: 0.107515\n[169]\tvalid_0's l1: 0.107251\n[170]\tvalid_0's l1: 0.106988\n[171]\tvalid_0's l1: 0.106701\n[172]\tvalid_0's l1: 0.10641\n[173]\tvalid_0's l1: 0.106163\n[174]\tvalid_0's l1: 0.105875\n[175]\tvalid_0's l1: 0.105621\n[176]\tvalid_0's l1: 0.105367\n[177]\tvalid_0's l1: 0.1051\n[178]\tvalid_0's l1: 0.104832\n[179]\tvalid_0's l1: 0.104587\n[180]\tvalid_0's l1: 0.104361\n[181]\tvalid_0's l1: 0.104121\n[182]\tvalid_0's l1: 0.103856\n[183]\tvalid_0's l1: 0.103633\n[184]\tvalid_0's l1: 0.1034\n[185]\tvalid_0's l1: 0.103151\n[186]\tvalid_0's l1: 0.102939\n[187]\tvalid_0's l1: 0.102703\n[188]\tvalid_0's l1: 0.102494\n[189]\tvalid_0's l1: 0.102291\n[190]\tvalid_0's l1: 0.102058\n[191]\tvalid_0's l1: 0.101857\n[192]\tvalid_0's l1: 0.101678\n[193]\tvalid_0's l1: 0.101485\n[194]\tvalid_0's l1: 0.101271\n[195]\tvalid_0's l1: 0.101049\n[196]\tvalid_0's l1: 0.100845\n[197]\tvalid_0's l1: 0.100636\n[198]\tvalid_0's l1: 0.100423\n[199]\tvalid_0's l1: 0.100226\n[200]\tvalid_0's l1: 0.100024\n[201]\tvalid_0's l1: 0.0998238\n[202]\tvalid_0's l1: 0.099624\n[203]\tvalid_0's l1: 0.0994529\n[204]\tvalid_0's l1: 0.09928\n[205]\tvalid_0's l1: 0.0990979\n[206]\tvalid_0's l1: 0.0989662\n[207]\tvalid_0's l1: 0.0988031\n[208]\tvalid_0's l1: 0.0986307\n[209]\tvalid_0's l1: 0.0984775\n[210]\tvalid_0's l1: 0.0983194\n[211]\tvalid_0's l1: 0.0981604\n[212]\tvalid_0's l1: 0.0980163\n[213]\tvalid_0's l1: 0.0978612\n[214]\tvalid_0's l1: 0.0977006\n[215]\tvalid_0's l1: 0.0975406\n[216]\tvalid_0's l1: 0.0973952\n[217]\tvalid_0's l1: 0.0972422\n[218]\tvalid_0's l1: 0.09712\n[219]\tvalid_0's l1: 0.0969777\n[220]\tvalid_0's l1: 0.0968363\n[221]\tvalid_0's l1: 0.0967148\n[222]\tvalid_0's l1: 0.0965852\n[223]\tvalid_0's l1: 0.0964475\n[224]\tvalid_0's l1: 0.0963338\n[225]\tvalid_0's l1: 0.0962159\n[226]\tvalid_0's l1: 0.096095\n[227]\tvalid_0's l1: 0.0959925\n[228]\tvalid_0's l1: 0.0958848\n[229]\tvalid_0's l1: 0.0957708\n[230]\tvalid_0's l1: 0.0956536\n[231]\tvalid_0's l1: 0.0955532\n[232]\tvalid_0's l1: 0.0954651\n[233]\tvalid_0's l1: 0.09537\n[234]\tvalid_0's l1: 0.0952919\n[235]\tvalid_0's l1: 0.095167\n[236]\tvalid_0's l1: 0.0951043\n[237]\tvalid_0's l1: 0.0950082\n[238]\tvalid_0's l1: 0.0949369\n[239]\tvalid_0's l1: 0.0948474\n[240]\tvalid_0's l1: 0.0947515\n[241]\tvalid_0's l1: 0.0946653\n[242]\tvalid_0's l1: 0.0945561\n[243]\tvalid_0's l1: 0.094471\n[244]\tvalid_0's l1: 0.0944103\n[245]\tvalid_0's l1: 0.0943363\n[246]\tvalid_0's l1: 0.0942521\n[247]\tvalid_0's l1: 0.0941612\n[248]\tvalid_0's l1: 0.0940989\n[249]\tvalid_0's l1: 0.0940417\n[250]\tvalid_0's l1: 0.0939767\n[251]\tvalid_0's l1: 0.093909\n[252]\tvalid_0's l1: 0.0938259\n[253]\tvalid_0's l1: 0.0937651\n[254]\tvalid_0's l1: 0.0936753\n[255]\tvalid_0's l1: 0.0936216\n[256]\tvalid_0's l1: 0.0935463\n[257]\tvalid_0's l1: 0.0934621\n[258]\tvalid_0's l1: 0.0933781\n[259]\tvalid_0's l1: 0.093283\n[260]\tvalid_0's l1: 0.0932099\n[261]\tvalid_0's l1: 0.0931545\n[262]\tvalid_0's l1: 0.093072\n[263]\tvalid_0's l1: 0.0930184\n[264]\tvalid_0's l1: 0.0929375\n[265]\tvalid_0's l1: 0.092895\n[266]\tvalid_0's l1: 0.0928399\n[267]\tvalid_0's l1: 0.0927741\n[268]\tvalid_0's l1: 0.0927304\n[269]\tvalid_0's l1: 0.0926626\n[270]\tvalid_0's l1: 0.0926117\n[271]\tvalid_0's l1: 0.0925693\n[272]\tvalid_0's l1: 0.0925075\n[273]\tvalid_0's l1: 0.0924633\n[274]\tvalid_0's l1: 0.0924024\n[275]\tvalid_0's l1: 0.0923531\n[276]\tvalid_0's l1: 0.0923024\n[277]\tvalid_0's l1: 0.0922478\n[278]\tvalid_0's l1: 0.0922115\n[279]\tvalid_0's l1: 0.0921735\n[280]\tvalid_0's l1: 0.0921302\n[281]\tvalid_0's l1: 0.0920761\n[282]\tvalid_0's l1: 0.0920206\n[283]\tvalid_0's l1: 0.0919901\n[284]\tvalid_0's l1: 0.091957\n[285]\tvalid_0's l1: 0.0919144\n[286]\tvalid_0's l1: 0.0918701\n[287]\tvalid_0's l1: 0.0918356\n[288]\tvalid_0's l1: 0.0917941\n[289]\tvalid_0's l1: 0.09175\n[290]\tvalid_0's l1: 0.0917162\n[291]\tvalid_0's l1: 0.0916785\n[292]\tvalid_0's l1: 0.0916395\n[293]\tvalid_0's l1: 0.0916023\n[294]\tvalid_0's l1: 0.0915509\n[295]\tvalid_0's l1: 0.0915099\n[296]\tvalid_0's l1: 0.0914732\n[297]\tvalid_0's l1: 0.0914282\n[298]\tvalid_0's l1: 0.0913879\n[299]\tvalid_0's l1: 0.0913488\n[300]\tvalid_0's l1: 0.0913118\n[301]\tvalid_0's l1: 0.0912829\n[302]\tvalid_0's l1: 0.0912503\n[303]\tvalid_0's l1: 0.0912177\n[304]\tvalid_0's l1: 0.0911977\n[305]\tvalid_0's l1: 0.0911801\n[306]\tvalid_0's l1: 0.0911608\n[307]\tvalid_0's l1: 0.0911349\n[308]\tvalid_0's l1: 0.0911071\n[309]\tvalid_0's l1: 0.0910805\n[310]\tvalid_0's l1: 0.0910565\n[311]\tvalid_0's l1: 0.0910343\n[312]\tvalid_0's l1: 0.0910137\n[313]\tvalid_0's l1: 0.09099\n[314]\tvalid_0's l1: 0.0909735\n[315]\tvalid_0's l1: 0.0909452\n[316]\tvalid_0's l1: 0.0909238\n[317]\tvalid_0's l1: 0.0909093\n[318]\tvalid_0's l1: 0.0908827\n[319]\tvalid_0's l1: 0.0908651\n[320]\tvalid_0's l1: 0.0908339\n[321]\tvalid_0's l1: 0.0908127\n[322]\tvalid_0's l1: 0.0907813\n[323]\tvalid_0's l1: 0.0907545\n[324]\tvalid_0's l1: 0.09071\n[325]\tvalid_0's l1: 0.0906794\n[326]\tvalid_0's l1: 0.0906727\n[327]\tvalid_0's l1: 0.0906314\n[328]\tvalid_0's l1: 0.0905927\n[329]\tvalid_0's l1: 0.0905788\n[330]\tvalid_0's l1: 0.0905529\n[331]\tvalid_0's l1: 0.0905405\n[332]\tvalid_0's l1: 0.0904965\n[333]\tvalid_0's l1: 0.0904619\n[334]\tvalid_0's l1: 0.0904401\n[335]\tvalid_0's l1: 0.0904207\n[336]\tvalid_0's l1: 0.0903813\n[337]\tvalid_0's l1: 0.0903662\n[338]\tvalid_0's l1: 0.0903522\n[339]\tvalid_0's l1: 0.0903515\n[340]\tvalid_0's l1: 0.0903274\n[341]\tvalid_0's l1: 0.0902977\n[342]\tvalid_0's l1: 0.0902716\n[343]\tvalid_0's l1: 0.0902535\n[344]\tvalid_0's l1: 0.0902365\n[345]\tvalid_0's l1: 0.0902455\n[346]\tvalid_0's l1: 0.0902215\n[347]\tvalid_0's l1: 0.0901999\n[348]\tvalid_0's l1: 0.0901837\n[349]\tvalid_0's l1: 0.090176\n[350]\tvalid_0's l1: 0.0901555\n[351]\tvalid_0's l1: 0.0901345\n[352]\tvalid_0's l1: 0.0901229\n[353]\tvalid_0's l1: 0.0901324\n[354]\tvalid_0's l1: 0.0901214\n[355]\tvalid_0's l1: 0.0900852\n[356]\tvalid_0's l1: 0.0900633\n[357]\tvalid_0's l1: 0.0900412\n[358]\tvalid_0's l1: 0.0900136\n","name":"stdout"},{"output_type":"stream","text":"[359]\tvalid_0's l1: 0.090011\n[360]\tvalid_0's l1: 0.0899766\n[361]\tvalid_0's l1: 0.0899574\n[362]\tvalid_0's l1: 0.0899558\n[363]\tvalid_0's l1: 0.0899273\n[364]\tvalid_0's l1: 0.089908\n[365]\tvalid_0's l1: 0.0898762\n[366]\tvalid_0's l1: 0.0898648\n[367]\tvalid_0's l1: 0.0898513\n[368]\tvalid_0's l1: 0.0898215\n[369]\tvalid_0's l1: 0.0898093\n[370]\tvalid_0's l1: 0.0897901\n[371]\tvalid_0's l1: 0.0897714\n[372]\tvalid_0's l1: 0.0897598\n[373]\tvalid_0's l1: 0.0897266\n[374]\tvalid_0's l1: 0.0896983\n[375]\tvalid_0's l1: 0.0896897\n[376]\tvalid_0's l1: 0.0896802\n[377]\tvalid_0's l1: 0.0896695\n[378]\tvalid_0's l1: 0.0896386\n[379]\tvalid_0's l1: 0.0896135\n[380]\tvalid_0's l1: 0.0896009\n[381]\tvalid_0's l1: 0.0895952\n[382]\tvalid_0's l1: 0.0895686\n[383]\tvalid_0's l1: 0.089557\n[384]\tvalid_0's l1: 0.089547\n[385]\tvalid_0's l1: 0.0895224\n[386]\tvalid_0's l1: 0.0895161\n[387]\tvalid_0's l1: 0.0894992\n[388]\tvalid_0's l1: 0.0894682\n[389]\tvalid_0's l1: 0.0894574\n[390]\tvalid_0's l1: 0.0894373\n[391]\tvalid_0's l1: 0.0894072\n[392]\tvalid_0's l1: 0.0894031\n[393]\tvalid_0's l1: 0.0893895\n[394]\tvalid_0's l1: 0.0893574\n[395]\tvalid_0's l1: 0.0893359\n[396]\tvalid_0's l1: 0.0893193\n[397]\tvalid_0's l1: 0.0893152\n[398]\tvalid_0's l1: 0.089302\n[399]\tvalid_0's l1: 0.0892857\n[400]\tvalid_0's l1: 0.0892746\n[401]\tvalid_0's l1: 0.0892609\n[402]\tvalid_0's l1: 0.0892511\n[403]\tvalid_0's l1: 0.0892339\n[404]\tvalid_0's l1: 0.0892066\n[405]\tvalid_0's l1: 0.0891901\n[406]\tvalid_0's l1: 0.0891954\n[407]\tvalid_0's l1: 0.0891819\n[408]\tvalid_0's l1: 0.0891838\n[409]\tvalid_0's l1: 0.0891826\n[410]\tvalid_0's l1: 0.08916\n[411]\tvalid_0's l1: 0.0891498\n[412]\tvalid_0's l1: 0.0891327\n[413]\tvalid_0's l1: 0.0891351\n[414]\tvalid_0's l1: 0.0891201\n[415]\tvalid_0's l1: 0.0890989\n[416]\tvalid_0's l1: 0.089094\n[417]\tvalid_0's l1: 0.0890921\n[418]\tvalid_0's l1: 0.089086\n[419]\tvalid_0's l1: 0.0890872\n[420]\tvalid_0's l1: 0.0890591\n[421]\tvalid_0's l1: 0.0890406\n[422]\tvalid_0's l1: 0.0890443\n[423]\tvalid_0's l1: 0.0890211\n[424]\tvalid_0's l1: 0.0890123\n[425]\tvalid_0's l1: 0.0890074\n[426]\tvalid_0's l1: 0.0890161\n[427]\tvalid_0's l1: 0.089002\n[428]\tvalid_0's l1: 0.0889736\n[429]\tvalid_0's l1: 0.0889618\n[430]\tvalid_0's l1: 0.0889541\n[431]\tvalid_0's l1: 0.088943\n[432]\tvalid_0's l1: 0.0889295\n[433]\tvalid_0's l1: 0.0889215\n[434]\tvalid_0's l1: 0.0889258\n[435]\tvalid_0's l1: 0.0889198\n[436]\tvalid_0's l1: 0.0888921\n[437]\tvalid_0's l1: 0.0888856\n[438]\tvalid_0's l1: 0.0888786\n[439]\tvalid_0's l1: 0.0888642\n[440]\tvalid_0's l1: 0.0888434\n[441]\tvalid_0's l1: 0.0888273\n[442]\tvalid_0's l1: 0.0888359\n[443]\tvalid_0's l1: 0.0888081\n[444]\tvalid_0's l1: 0.0888175\n[445]\tvalid_0's l1: 0.0887966\n[446]\tvalid_0's l1: 0.0887908\n[447]\tvalid_0's l1: 0.0887704\n[448]\tvalid_0's l1: 0.0887522\n[449]\tvalid_0's l1: 0.0887614\n[450]\tvalid_0's l1: 0.088764\n[451]\tvalid_0's l1: 0.0887453\n[452]\tvalid_0's l1: 0.0887293\n[453]\tvalid_0's l1: 0.0887189\n[454]\tvalid_0's l1: 0.0886966\n[455]\tvalid_0's l1: 0.0886877\n[456]\tvalid_0's l1: 0.088684\n[457]\tvalid_0's l1: 0.0886806\n[458]\tvalid_0's l1: 0.0886802\n[459]\tvalid_0's l1: 0.0886733\n[460]\tvalid_0's l1: 0.0886574\n[461]\tvalid_0's l1: 0.0886622\n[462]\tvalid_0's l1: 0.0886445\n[463]\tvalid_0's l1: 0.0886446\n[464]\tvalid_0's l1: 0.0886343\n[465]\tvalid_0's l1: 0.088634\n[466]\tvalid_0's l1: 0.0886179\n[467]\tvalid_0's l1: 0.0886018\n[468]\tvalid_0's l1: 0.088602\n[469]\tvalid_0's l1: 0.0885912\n[470]\tvalid_0's l1: 0.0885831\n[471]\tvalid_0's l1: 0.0885837\n[472]\tvalid_0's l1: 0.0885686\n[473]\tvalid_0's l1: 0.0885681\n[474]\tvalid_0's l1: 0.088564\n[475]\tvalid_0's l1: 0.0885646\n[476]\tvalid_0's l1: 0.0885625\n[477]\tvalid_0's l1: 0.088552\n[478]\tvalid_0's l1: 0.0885448\n[479]\tvalid_0's l1: 0.0885503\n[480]\tvalid_0's l1: 0.0885573\n[481]\tvalid_0's l1: 0.0885614\n[482]\tvalid_0's l1: 0.0885499\n[483]\tvalid_0's l1: 0.0885607\n[484]\tvalid_0's l1: 0.0885609\n[485]\tvalid_0's l1: 0.0885516\n[486]\tvalid_0's l1: 0.0885335\n[487]\tvalid_0's l1: 0.0885211\n[488]\tvalid_0's l1: 0.0885188\n[489]\tvalid_0's l1: 0.0885233\n[490]\tvalid_0's l1: 0.0885226\n[491]\tvalid_0's l1: 0.0885166\n[492]\tvalid_0's l1: 0.0885039\n[493]\tvalid_0's l1: 0.0884824\n[494]\tvalid_0's l1: 0.0884755\n[495]\tvalid_0's l1: 0.0884716\n[496]\tvalid_0's l1: 0.0884665\n[497]\tvalid_0's l1: 0.0884726\n[498]\tvalid_0's l1: 0.0884753\n[499]\tvalid_0's l1: 0.0884691\n[500]\tvalid_0's l1: 0.0884668\n[501]\tvalid_0's l1: 0.0884609\n[502]\tvalid_0's l1: 0.0884722\n[503]\tvalid_0's l1: 0.088458\n[504]\tvalid_0's l1: 0.0884557\n[505]\tvalid_0's l1: 0.0884625\n[506]\tvalid_0's l1: 0.0884512\n[507]\tvalid_0's l1: 0.0884467\n[508]\tvalid_0's l1: 0.0884541\n[509]\tvalid_0's l1: 0.0884456\n[510]\tvalid_0's l1: 0.0884586\n[511]\tvalid_0's l1: 0.0884508\n[512]\tvalid_0's l1: 0.0884467\n[513]\tvalid_0's l1: 0.0884392\n[514]\tvalid_0's l1: 0.0884385\n[515]\tvalid_0's l1: 0.0884381\n[516]\tvalid_0's l1: 0.0884329\n[517]\tvalid_0's l1: 0.0884255\n[518]\tvalid_0's l1: 0.0884392\n[519]\tvalid_0's l1: 0.0884252\n[520]\tvalid_0's l1: 0.0884358\n[521]\tvalid_0's l1: 0.0884336\n[522]\tvalid_0's l1: 0.088447\n[523]\tvalid_0's l1: 0.0884342\n[524]\tvalid_0's l1: 0.0884316\n[525]\tvalid_0's l1: 0.0884252\n[526]\tvalid_0's l1: 0.0884222\n[527]\tvalid_0's l1: 0.0884162\n[528]\tvalid_0's l1: 0.0884314\n[529]\tvalid_0's l1: 0.0884275\n[530]\tvalid_0's l1: 0.0884209\n[531]\tvalid_0's l1: 0.0884233\n[532]\tvalid_0's l1: 0.0884132\n[533]\tvalid_0's l1: 0.0884052\n[534]\tvalid_0's l1: 0.0883964\n[535]\tvalid_0's l1: 0.088407\n[536]\tvalid_0's l1: 0.0884228\n[537]\tvalid_0's l1: 0.0884131\n[538]\tvalid_0's l1: 0.0884159\n[539]\tvalid_0's l1: 0.0884033\n[540]\tvalid_0's l1: 0.0884085\n[541]\tvalid_0's l1: 0.0883996\n[542]\tvalid_0's l1: 0.0883944\n[543]\tvalid_0's l1: 0.0883953\n[544]\tvalid_0's l1: 0.08841\n[545]\tvalid_0's l1: 0.0884161\n[546]\tvalid_0's l1: 0.0884112\n[547]\tvalid_0's l1: 0.0884046\n[548]\tvalid_0's l1: 0.0884155\n[549]\tvalid_0's l1: 0.088409\n[550]\tvalid_0's l1: 0.0884055\n[551]\tvalid_0's l1: 0.0884032\n[552]\tvalid_0's l1: 0.0883921\n[553]\tvalid_0's l1: 0.0884029\n[554]\tvalid_0's l1: 0.0884099\n[555]\tvalid_0's l1: 0.0884126\n[556]\tvalid_0's l1: 0.0884076\n[557]\tvalid_0's l1: 0.0884029\n[558]\tvalid_0's l1: 0.088409\n[559]\tvalid_0's l1: 0.0883998\n[560]\tvalid_0's l1: 0.0883916\n[561]\tvalid_0's l1: 0.0883887\n[562]\tvalid_0's l1: 0.0883845\n[563]\tvalid_0's l1: 0.0883788\n[564]\tvalid_0's l1: 0.0883684\n[565]\tvalid_0's l1: 0.0883564\n[566]\tvalid_0's l1: 0.0883628\n[567]\tvalid_0's l1: 0.0883468\n[568]\tvalid_0's l1: 0.0883389\n[569]\tvalid_0's l1: 0.0883396\n[570]\tvalid_0's l1: 0.088323\n[571]\tvalid_0's l1: 0.0883181\n[572]\tvalid_0's l1: 0.088313\n[573]\tvalid_0's l1: 0.088304\n[574]\tvalid_0's l1: 0.0883025\n[575]\tvalid_0's l1: 0.0883127\n[576]\tvalid_0's l1: 0.0883017\n[577]\tvalid_0's l1: 0.0882993\n[578]\tvalid_0's l1: 0.0882845\n[579]\tvalid_0's l1: 0.0882787\n[580]\tvalid_0's l1: 0.0882675\n[581]\tvalid_0's l1: 0.088264\n[582]\tvalid_0's l1: 0.0882738\n[583]\tvalid_0's l1: 0.0882654\n[584]\tvalid_0's l1: 0.088252\n[585]\tvalid_0's l1: 0.0882355\n[586]\tvalid_0's l1: 0.0882466\n[587]\tvalid_0's l1: 0.0882552\n[588]\tvalid_0's l1: 0.0882658\n[589]\tvalid_0's l1: 0.0882607\n[590]\tvalid_0's l1: 0.0882589\n[591]\tvalid_0's l1: 0.0882563\n[592]\tvalid_0's l1: 0.0882337\n[593]\tvalid_0's l1: 0.0882258\n[594]\tvalid_0's l1: 0.0882247\n[595]\tvalid_0's l1: 0.0882209\n[596]\tvalid_0's l1: 0.0882106\n[597]\tvalid_0's l1: 0.0882036\n[598]\tvalid_0's l1: 0.0882088\n[599]\tvalid_0's l1: 0.0881917\n[600]\tvalid_0's l1: 0.088191\n[601]\tvalid_0's l1: 0.0881805\n[602]\tvalid_0's l1: 0.0881753\n[603]\tvalid_0's l1: 0.088186\n[604]\tvalid_0's l1: 0.0881941\n[605]\tvalid_0's l1: 0.0882007\n[606]\tvalid_0's l1: 0.0881949\n[607]\tvalid_0's l1: 0.0881843\n[608]\tvalid_0's l1: 0.0881824\n[609]\tvalid_0's l1: 0.0881674\n[610]\tvalid_0's l1: 0.0881593\n[611]\tvalid_0's l1: 0.0881515\n[612]\tvalid_0's l1: 0.0881422\n[613]\tvalid_0's l1: 0.0881404\n[614]\tvalid_0's l1: 0.0881433\n[615]\tvalid_0's l1: 0.0881454\n[616]\tvalid_0's l1: 0.0881495\n[617]\tvalid_0's l1: 0.0881394\n[618]\tvalid_0's l1: 0.0881364\n[619]\tvalid_0's l1: 0.0881229\n[620]\tvalid_0's l1: 0.0881249\n[621]\tvalid_0's l1: 0.0881311\n[622]\tvalid_0's l1: 0.0881249\n[623]\tvalid_0's l1: 0.088126\n[624]\tvalid_0's l1: 0.0881289\n[625]\tvalid_0's l1: 0.0881254\n[626]\tvalid_0's l1: 0.0881173\n[627]\tvalid_0's l1: 0.0881191\n[628]\tvalid_0's l1: 0.0881193\n[629]\tvalid_0's l1: 0.0881276\n[630]\tvalid_0's l1: 0.0881122\n[631]\tvalid_0's l1: 0.0880991\n[632]\tvalid_0's l1: 0.0881\n[633]\tvalid_0's l1: 0.0880981\n[634]\tvalid_0's l1: 0.0881019\n[635]\tvalid_0's l1: 0.0880921\n[636]\tvalid_0's l1: 0.0880855\n[637]\tvalid_0's l1: 0.0880793\n[638]\tvalid_0's l1: 0.0880871\n[639]\tvalid_0's l1: 0.0880808\n[640]\tvalid_0's l1: 0.08808\n[641]\tvalid_0's l1: 0.0880788\n[642]\tvalid_0's l1: 0.0880843\n[643]\tvalid_0's l1: 0.0880896\n[644]\tvalid_0's l1: 0.0880998\n[645]\tvalid_0's l1: 0.0880885\n[646]\tvalid_0's l1: 0.0880952\n[647]\tvalid_0's l1: 0.0880983\n[648]\tvalid_0's l1: 0.0881038\n[649]\tvalid_0's l1: 0.0881023\n[650]\tvalid_0's l1: 0.088097\n[651]\tvalid_0's l1: 0.0881056\n[652]\tvalid_0's l1: 0.0881109\n[653]\tvalid_0's l1: 0.0881067\n[654]\tvalid_0's l1: 0.0881063\n[655]\tvalid_0's l1: 0.0881118\n[656]\tvalid_0's l1: 0.0881182\n[657]\tvalid_0's l1: 0.0881146\n[658]\tvalid_0's l1: 0.0881022\n[659]\tvalid_0's l1: 0.0881057\n[660]\tvalid_0's l1: 0.0881101\n[661]\tvalid_0's l1: 0.0881117\n[662]\tvalid_0's l1: 0.0881072\n[663]\tvalid_0's l1: 0.0881105\n","name":"stdout"},{"output_type":"stream","text":"[664]\tvalid_0's l1: 0.088103\n[665]\tvalid_0's l1: 0.088096\n[666]\tvalid_0's l1: 0.0880995\n[667]\tvalid_0's l1: 0.0881049\n[668]\tvalid_0's l1: 0.0881079\n[669]\tvalid_0's l1: 0.0881021\n[670]\tvalid_0's l1: 0.088098\n[671]\tvalid_0's l1: 0.0881054\n[672]\tvalid_0's l1: 0.088112\n[673]\tvalid_0's l1: 0.0881174\n[674]\tvalid_0's l1: 0.0881289\n[675]\tvalid_0's l1: 0.088125\n[676]\tvalid_0's l1: 0.0881326\n[677]\tvalid_0's l1: 0.0881393\n[678]\tvalid_0's l1: 0.0881454\n[679]\tvalid_0's l1: 0.0881486\n[680]\tvalid_0's l1: 0.0881471\n[681]\tvalid_0's l1: 0.0881539\n[682]\tvalid_0's l1: 0.0881528\n[683]\tvalid_0's l1: 0.0881594\n[684]\tvalid_0's l1: 0.0881634\n[685]\tvalid_0's l1: 0.0881669\n[686]\tvalid_0's l1: 0.0881728\n[687]\tvalid_0's l1: 0.0881759\n[688]\tvalid_0's l1: 0.0881923\n[689]\tvalid_0's l1: 0.0881988\n[690]\tvalid_0's l1: 0.0882022\n[691]\tvalid_0's l1: 0.0881989\n[692]\tvalid_0's l1: 0.0881992\n[693]\tvalid_0's l1: 0.088207\n[694]\tvalid_0's l1: 0.0882145\n[695]\tvalid_0's l1: 0.0882136\n[696]\tvalid_0's l1: 0.0882165\n[697]\tvalid_0's l1: 0.0882183\n[698]\tvalid_0's l1: 0.0882246\n[699]\tvalid_0's l1: 0.0882231\n[700]\tvalid_0's l1: 0.0882278\n[701]\tvalid_0's l1: 0.0882312\n[702]\tvalid_0's l1: 0.0882313\n[703]\tvalid_0's l1: 0.0882396\n[704]\tvalid_0's l1: 0.0882431\n[705]\tvalid_0's l1: 0.0882568\n[706]\tvalid_0's l1: 0.0882622\n[707]\tvalid_0's l1: 0.0882575\n[708]\tvalid_0's l1: 0.0882493\n[709]\tvalid_0's l1: 0.0882484\n[710]\tvalid_0's l1: 0.0882632\n[711]\tvalid_0's l1: 0.0882684\n[712]\tvalid_0's l1: 0.0882584\n[713]\tvalid_0's l1: 0.088261\n[714]\tvalid_0's l1: 0.0882641\n[715]\tvalid_0's l1: 0.0882644\n[716]\tvalid_0's l1: 0.0882645\n[717]\tvalid_0's l1: 0.0882568\n[718]\tvalid_0's l1: 0.088254\n[719]\tvalid_0's l1: 0.0882474\n[720]\tvalid_0's l1: 0.0882478\n[721]\tvalid_0's l1: 0.0882454\n[722]\tvalid_0's l1: 0.0882539\n[723]\tvalid_0's l1: 0.0882469\n[724]\tvalid_0's l1: 0.0882523\n[725]\tvalid_0's l1: 0.0882544\n[726]\tvalid_0's l1: 0.0882507\n[727]\tvalid_0's l1: 0.0882482\n[728]\tvalid_0's l1: 0.0882495\n[729]\tvalid_0's l1: 0.0882466\n[730]\tvalid_0's l1: 0.0882564\n[731]\tvalid_0's l1: 0.0882595\n[732]\tvalid_0's l1: 0.088248\n[733]\tvalid_0's l1: 0.0882532\n[734]\tvalid_0's l1: 0.0882506\n[735]\tvalid_0's l1: 0.0882451\n[736]\tvalid_0's l1: 0.088246\n[737]\tvalid_0's l1: 0.0882484\n[738]\tvalid_0's l1: 0.0882594\n[739]\tvalid_0's l1: 0.0882642\n[740]\tvalid_0's l1: 0.0882673\n[741]\tvalid_0's l1: 0.0882742\nEarly stopping, best iteration is:\n[641]\tvalid_0's l1: 0.0880788\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n  if getattr(data, 'base', None) is not None and \\\n","name":"stderr"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}